{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b97e2c",
   "metadata": {},
   "source": [
    "Passo 3 - Gerar a visão geral das modularidades identificadas após os calculos feitos no Gephi\n",
    "\n",
    "Notebook responsável criar a visão geral da análise de modularidades encontradas na extração dos tweets feitos no passo 1, a partir dos dados calculados pelo Gephi "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94f41f1",
   "metadata": {},
   "source": [
    "Declarar as libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "322c567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dataframe_image as dfi\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import ImageColorGenerator\n",
    "from wordcloud import STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "import tweepy\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9af85de",
   "metadata": {},
   "source": [
    "Inserir o token de autenticação do Twitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "f1ddb440",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token='Insira o token de acesso', wait_on_rate_limit=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3838e34",
   "metadata": {},
   "source": [
    "Definição dos arquivos de entrada do processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f37f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotulo = \"Nome do Arquivo\" # nome do arquivo que será usado como padrão para criação dos arquivos\n",
    "data_pesquisa = \"0101\" # data referencia usada para criação dos arquivos\n",
    "save_path = 'C:\\\\diretório\\\\' # diretório padrão para criação dos arquivos\n",
    "arq_gephi = save_path + \"\\\\\" + rotulo + \"\\\\\" + 'gephi_' + rotulo + '.csv'\n",
    "arq_fonte = save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + '_CR_'+ data_pesquisa + '_raw.csv'\n",
    "arq_contas_brasil = 'twitter_contas_br_2022_v3.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d4070",
   "metadata": {},
   "source": [
    "Leitura dos arquivos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "b6425e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv(arq_contas_brasil, sep=';', low_memory = False, index_col=False)\n",
    "df_a = pd.read_csv(arq_gephi, low_memory = False, index_col=False)\n",
    "df_b = pd.read_csv(arq_fonte, low_memory = False, index_col=False)\n",
    "\n",
    "df_a_trab = pd.DataFrame(df_a, columns = [\"Id\", \"modularity_class\"]) \n",
    "\n",
    "df_a_trab['Id_convert'] = df_a_trab['Id'].astype(str)\n",
    "\n",
    "df_b_trab = pd.DataFrame(df_b, columns = [\"author_id\", \"text\"]) \n",
    "\n",
    "df_b_trab['Id_convert'] = df_b_trab['author_id'].astype(str)\n",
    "\n",
    "df_b_trab.rename(columns = {'author_id':'Id'}, inplace = True)\n",
    "\n",
    "df_merge_inner = pd.merge(df_a_trab, df_b_trab, how = 'inner', on = 'Id_convert')\n",
    "\n",
    "df_merge_inner.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe54156",
   "metadata": {},
   "source": [
    "Preparação dos dados para gerar Nuvem de Palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "d561e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Lista_palavras = [\"vai\",\"agora\",\"HTTPS\",\"Se\", \"O\", \"ao\",\"de\",\"a\",\"o\",\"que\",\"e\",\"do\",\"da\",\"em\",\"um\",\"para\",\"é\",\"com\",\"não\",\"uma\",\"os\",\"no\",\"se\",\"na\",\"por\",\"mais\",\"as\",\"dos\",\"como\",\"mas\",\"foi\",\"ao\",\"ele\",\"das\",\"tem\",\"à\",\"seu\",\"sua\",\"ou\",\"ser\",\"quando\",\"muito\",\"há\",\"nos\",\"já\",\"está\",\"eu\",\"também\",\"só\",\"pelo\",\"pela\",\"até\",\"isso\",\"ela\",\"entre\",\"era\",\"depois\",\"sem\",\"mesmo\",\"aos\",\"ter\",\"seus\",\"quem\",\"nas\",\"me\",\"esse\",\"eles\",\"estão\",\"você\",\"tinha\",\"foram\",\"essa\",\"num\",\"nem\",\"suas\",\"meu\",\"às\",\"minha\",\"têm\",\"numa\",\"pelos\",\"elas\",\"havia\",\"seja\",\"qual\",\"será\",\"nós\",\"tenho\",\"lhe\",\"deles\",\"essas\",\"esses\",\"pelas\",\"este\",\"fosse\",\"dele\",\"tu\",\"te\",\"vocês\",\"vos\",\"lhes\",\"meus\",\"minhas\",\"teu\",\"tua\",\"teus\",\"tuas\",\"nosso\",\"nossa\",\"nossos\",\"nossas\",\"dela\",\"delas\",\"esta\",\"estes\",\"estas\",\"aquele\",\"aquela\",\"aqueles\",\"aquelas\",\"isto\",\"aquilo\",\"estou\",\"está\",\"estamos\",\"estão\",\"estive\",\"esteve\",\"estivemos\",\"estiveram\",\"estava\",\"estávamos\",\"estavam\",\"estivera\",\"estivéramos\",\"esteja\",\"estejamos\",\"estejam\",\"estivesse\",\"estivéssemos\",\"estivessem\",\"estiver\",\"estivermos\",\"estiverem\",\"hei\",\"há\",\"havemos\",\"hão\",\"houve\",\"houvemos\",\"houveram\",\"houvera\",\"houvéramos\",\"haja\",\"hajamos\",\"hajam\",\"houvesse\",\"houvéssemos\",\"houvessem\",\"houver\",\"houvermos\",\"houverem\",\"houverei\",\"houverá\",\"houveremos\",\"houverão\",\"houveria\",\"houveríamos\",\"houveriam\",\"sou\",\"somos\",\"são\",\"era\",\"éramos\",\"eram\",\"fui\",\"foi\",\"fomos\",\"foram\",\"fora\",\"fôramos\",\"seja\",\"sejamos\",\"sejam\",\"fosse\",\"fôssemos\",\"fossem\",\"for\",\"formos\",\"forem\",\"serei\",\"será\",\"seremos\",\"serão\",\"seria\",\"seríamos\",\"seriam\",\"tenho\",\"tem\",\"temos\",\"tém\",\"tinha\",\"tínhamos\",\"tinham\",\"tive\",\"teve\",\"tivemos\",\"tiveram\",\"tivera\",\"tivéramos\",\"tenha\",\"tenhamos\",\"tenham\",\"tivesse\",\"tivéssemos\",\"tivesse\",\"tiver\",\"tivermos\",\"tiverem\",\"terei\",\"terá\",\"teremos\",\"terão\",\"teria\",\"teríamos\",\"teriam\",\"Se\",\"RT\",\"se\",\"ao\", \"outro\", \"outra'\"]\n",
    "\n",
    "text = \" \".join(i for i in df_merge_inner.text)\n",
    "\n",
    "stop_words = Lista_palavras + list(STOPWORDS)\n",
    "regex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\" \n",
    "        u\"\\U0001F300-\\U0001F5FF\" \n",
    "        u\"\\U0001F680-\\U0001F6FF\" \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "\n",
    "text_limpo_a = re.sub(regex_pattern,'',text)\n",
    "\n",
    "re_list = ['@[A-Za-z0–9_]+', '#']\n",
    "combined_re = re.compile( '|'.join( re_list) )\n",
    "text_limpo_b = re.sub(combined_re,'',text_limpo_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4d1f72",
   "metadata": {},
   "source": [
    "Gerar Nuvem de Palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef14c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_words=100, collocation_threshold = 10, width = 1500, height = 1000, random_state = 42, collocations = False, colormap = 'tab10', stopwords = stop_words, background_color=\"white\").generate(text_limpo_b)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.title(\"Wordcloud - Dados Gerais / \")\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_wordcloud_geral.png\", format='png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66ac72",
   "metadata": {},
   "source": [
    "Identificar frenquencia das palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff9aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencia_palavras = FreqDist(text_limpo_b)\n",
    "frequencia_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35359931",
   "metadata": {},
   "source": [
    "Preparação dos dados para gerar as visões de centralidade de entrada (Inbound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a0a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_centralidade_inbound = df_a.query('indegree > 0 ')[['Id','eigencentrality', 'pageranks', 'Authority', 'weighted indegree', 'modularity_class']]\n",
    "df_a_centralidade_inbound = df_a_centralidade_inbound.sort_values(['weighted indegree'], ascending=[False])\n",
    "df_a_centralidade_inbound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c31fb",
   "metadata": {},
   "source": [
    "Gráfico de interpolação das centralidades de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = df_a_centralidade_inbound['eigencentrality']\n",
    "x = df_a_centralidade_inbound['pageranks']\n",
    "y = df_a_centralidade_inbound['Authority']\n",
    " \n",
    "fig = plt.figure(figsize = (10, 8))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "   \n",
    "ax.grid( color ='grey', \n",
    "        linestyle ='-.', linewidth = 0.3, \n",
    "        alpha = 0.2) \n",
    " \n",
    " \n",
    "my_cmap = plt.get_cmap('hsv')\n",
    " \n",
    "sctt = ax.scatter3D(x, y, z,\n",
    "                    alpha = 0.8,\n",
    "                    c = (x + y + z), \n",
    "                    s =100,\n",
    "                    cmap = my_cmap, \n",
    "                    marker ='o')\n",
    " \n",
    "plt.title(\"Centralidades aplicadas aos Nodes - Modularidade\")\n",
    "ax.set_xlabel('pageranks', fontweight ='bold') \n",
    "ax.set_ylabel('Authority', fontweight ='bold') \n",
    "ax.set_zlabel('eigencentrality', fontweight ='bold')\n",
    "plt.margins(0.2)\n",
    "plt.tight_layout()\n",
    " \n",
    "    \n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_centralidade_geral.png\", format='png')\n",
    "    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33626306",
   "metadata": {},
   "source": [
    "Geração dos arquivos de centralidade de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "f2a01317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['Id']=df_c['Id'].str.lower()\n",
    "df_a_centralidade_inbound['Id']=df_a_centralidade_inbound['Id'].str.lower()\n",
    "\n",
    "df_a_centralidade_inbound_classificado = df_a_centralidade_inbound.merge(df_c, on='Id', how='left')\n",
    "df_a_centralidade_inbound_classificado.head(11)\n",
    "\n",
    "csv_centralidade_geral = save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_Tabela Centralidade Geral.csv\"\n",
    "\n",
    "df_a_centralidade_inbound_classificado.head(11).to_csv(csv_centralidade_geral)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9bd78b",
   "metadata": {},
   "source": [
    "Preparação dos dados para gerar as visões de centralidade de saída (Outbound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b7c450",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_centralidade_outbound = df_a.query('outdegree > 0 ')[['Id', 'weighted outdegree', 'modularity_class']]\n",
    "df_a_centralidade_outbound = df_a_centralidade_outbound.sort_values(['weighted outdegree'], ascending=[False])\n",
    "df_c['Id']=df_c['Id'].str.lower()\n",
    "df_a_centralidade_outbound['Id']=df_a_centralidade_outbound['Id'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de792171",
   "metadata": {},
   "source": [
    "Geração dos arquivos de centralidade de saída - usuários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "33e095b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_centralidade_outbound_classificado = df_a_centralidade_outbound.merge(df_c, on='Id', how='left')\n",
    "df_a_centralidade_outbound_classificado.head(11)\n",
    "\n",
    "csv_Top10_senders = save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_Tabela TOP10 Outbound Users.csv\"\n",
    "df_a_centralidade_outbound_classificado.head(11).to_csv(csv_Top10_senders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7123daa",
   "metadata": {},
   "source": [
    "Geração dos arquivos de centralidade de saída - modularidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d47cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grupos_outbound = df_a_centralidade_outbound_classificado.groupby(['modularity_class']).sum()\n",
    "grupos_outbound = grupos_outbound.sort_values('weighted outdegree', ascending=False)\n",
    "grupos_outbound['percent_total'] = (grupos_outbound['weighted outdegree'] / grupos_outbound['weighted outdegree'].sum())*100\n",
    "grupos_outbound['weighted outdegree'].sum()\n",
    "grupos_outbound.head(11)\n",
    "csv_top10_comunidades = save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_Tabela TOP10 Outbound Comunidades.csv\"\n",
    "grupos_outbound.head(11).to_csv(csv_top10_comunidades)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c01760c",
   "metadata": {},
   "source": [
    "Geração de um gráfico de pizza para melhor visualização da distribuição das modularidades "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad845f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grafico = grupos_outbound.head(11)\n",
    "sizes = data_grafico['percent_total']\n",
    "\n",
    "m_explode = (0, 0.1, 0, 0)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, autopct='%1.1f%%', \n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal') \n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_grafico_pie_comunidades.png\", format='png')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08e2dc2",
   "metadata": {},
   "source": [
    "Passo 4 - Gerar a visão detalhada das 5 maiores modularidades identificadas após os calculos feitos no Gephi\n",
    "\n",
    "Notebook responsável criar a visão detalhada da análise das 4 maiores modularidades encontradas a partir do processamento do passo 2 (Gephi) e dos 5 maiores modularidades dentro de cada uma delas. \n",
    "\n",
    "Observações:\n",
    "\n",
    "Na fase 2 (Gephi) além do arquivo geral com o resultado do processamento, são gerados arquivos para as 4 maiores modularidades (clusters) identificadas. \n",
    "\n",
    "Através desses arquivos serão geradas visões para cada uma das 4 modularidades e suas respectivas 5 maiores modularidades. As informações serão:\n",
    "\n",
    "A.Nuvem de Palavras\n",
    "B.Gráfico de Interpolação de Centralidades\n",
    "c.10 contas com o maior grau de centralidade de entrada\n",
    "D.Para as 3 maiores contas são identificadas as mensagens as quais estavam sendo discutidas.\n",
    "\n",
    "Para facilitar a visualização e análise dos resultados optou-se por repetir o código para cada avaliação, de maneira que se pudesse \"rolar\" a visão dentro do notebook.\n",
    "\n",
    "Os nros identificadores dos clusters são encontrados a partir da análise dos dados do Gephi\n",
    "\n",
    "Esse código pode ser modificado de maneira acrescer ou diminuir o grau de avaliação de cada modularidade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1285620f",
   "metadata": {},
   "source": [
    "Declarar as libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5533598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dataframe_image as dfi\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import ImageColorGenerator\n",
    "from wordcloud import STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "import tweepy\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e279809",
   "metadata": {},
   "source": [
    "Configuração de Token de Acesso do Twitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4e32c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = tweepy.Client(bearer_token='Insira o token de acesso', wait_on_rate_limit=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6e103e",
   "metadata": {},
   "source": [
    "Definição dos arquivos de entrada do processamento e saida "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e461ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotulo = \"Nome do Arquivo\" # nome do arquivo que será usado como padrão para criação dos arquivos\n",
    "data_pesquisa = \"0101\" # data referencia usada para criação dos arquivos\n",
    "save_path = 'C:\\\\diretório\\\\' # diretório padrão para criação dos arquivos\n",
    "\n",
    "arq_gephi_mod1 = save_path + \"\\\\\" + rotulo + \"\\\\\" + 'gephi_' + rotulo + '_mod1.csv'\n",
    "arq_gephi_mod2 = save_path + \"\\\\\" + rotulo + \"\\\\\" + 'gephi_' + rotulo + '_mod2.csv'\n",
    "arq_gephi_mod3 = save_path + \"\\\\\" + rotulo + \"\\\\\" + 'gephi_' + rotulo + '_mod3.csv'\n",
    "arq_gephi_mod4 = save_path + \"\\\\\" + rotulo + \"\\\\\" + 'gephi_' + rotulo + '_mod4.csv'\n",
    "\n",
    "arq_fonte = save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + '_CR_'+ data_pesquisa + '_raw.csv'\n",
    "arq_contas_brasil = 'twitter_contas_br_2022_v3.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d73382",
   "metadata": {},
   "source": [
    "Inicio do Estudo da Modularidade 1 - Declaração das 5 maiores modularidades encontradas nesse grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d26f5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_01 = 0\n",
    "mod_02 = 2\n",
    "mod_03 = 1\n",
    "mod_04 = 3\n",
    "mod_05 = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f1a2f",
   "metadata": {},
   "source": [
    "Carga dos dados - Modularidade 1 / Modularidade 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e559b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv(arq_contas_brasil, sep=';', low_memory = False, index_col=False)\n",
    "\n",
    "modularidade = mod_01            \n",
    "\n",
    "df_a = pd.read_csv(arq_gephi_mod1, low_memory = False, index_col=False)\n",
    "df_b = pd.read_csv(arq_fonte, low_memory = False, index_col=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9717d",
   "metadata": {},
   "source": [
    "Adequação dos dados - Modularidade 1 / Modularidade 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b999a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_trab = pd.DataFrame(df_a, columns = [\"Id\", \"modularity_class\"]) \n",
    "df_a_trab = df_a_trab.query('modularity_class == @modularidade')[['Id', 'modularity_class']]\n",
    "df_a_trab['Id_convert'] = df_a_trab['Id'].astype(str)\n",
    "df_b_trab = pd.DataFrame(df_b, columns = [\"author_id\", \"text\"]) \n",
    "df_b_trab['Id_convert'] = df_b_trab['author_id'].astype(str)\n",
    "df_b_trab.rename(columns = {'author_id':'Id'}, inplace = True)\n",
    "df_merge_inner = pd.merge(df_a_trab, df_b_trab, how = 'inner', on = 'Id_convert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2bca7e",
   "metadata": {},
   "source": [
    "Nuvem de Palavras - Modularidade 1 / Modularidade 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65eb562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Lista_palavras = [\"vai\",\"agora\",\"HTTPS\",\"Se\", \"O\", \"ao\",\"de\",\"a\",\"o\",\"que\",\"e\",\"do\",\"da\",\"em\",\"um\",\"para\",\"é\",\"com\",\"não\",\"uma\",\"os\",\"no\",\"se\",\"na\",\"por\",\"mais\",\"as\",\"dos\",\"como\",\"mas\",\"foi\",\"ao\",\"ele\",\"das\",\"tem\",\"à\",\"seu\",\"sua\",\"ou\",\"ser\",\"quando\",\"muito\",\"há\",\"nos\",\"já\",\"está\",\"eu\",\"também\",\"só\",\"pelo\",\"pela\",\"até\",\"isso\",\"ela\",\"entre\",\"era\",\"depois\",\"sem\",\"mesmo\",\"aos\",\"ter\",\"seus\",\"quem\",\"nas\",\"me\",\"esse\",\"eles\",\"estão\",\"você\",\"tinha\",\"foram\",\"essa\",\"num\",\"nem\",\"suas\",\"meu\",\"às\",\"minha\",\"têm\",\"numa\",\"pelos\",\"elas\",\"havia\",\"seja\",\"qual\",\"será\",\"nós\",\"tenho\",\"lhe\",\"deles\",\"essas\",\"esses\",\"pelas\",\"este\",\"fosse\",\"dele\",\"tu\",\"te\",\"vocês\",\"vos\",\"lhes\",\"meus\",\"minhas\",\"teu\",\"tua\",\"teus\",\"tuas\",\"nosso\",\"nossa\",\"nossos\",\"nossas\",\"dela\",\"delas\",\"esta\",\"estes\",\"estas\",\"aquele\",\"aquela\",\"aqueles\",\"aquelas\",\"isto\",\"aquilo\",\"estou\",\"está\",\"estamos\",\"estão\",\"estive\",\"esteve\",\"estivemos\",\"estiveram\",\"estava\",\"estávamos\",\"estavam\",\"estivera\",\"estivéramos\",\"esteja\",\"estejamos\",\"estejam\",\"estivesse\",\"estivéssemos\",\"estivessem\",\"estiver\",\"estivermos\",\"estiverem\",\"hei\",\"há\",\"havemos\",\"hão\",\"houve\",\"houvemos\",\"houveram\",\"houvera\",\"houvéramos\",\"haja\",\"hajamos\",\"hajam\",\"houvesse\",\"houvéssemos\",\"houvessem\",\"houver\",\"houvermos\",\"houverem\",\"houverei\",\"houverá\",\"houveremos\",\"houverão\",\"houveria\",\"houveríamos\",\"houveriam\",\"sou\",\"somos\",\"são\",\"era\",\"éramos\",\"eram\",\"fui\",\"foi\",\"fomos\",\"foram\",\"fora\",\"fôramos\",\"seja\",\"sejamos\",\"sejam\",\"fosse\",\"fôssemos\",\"fossem\",\"for\",\"formos\",\"forem\",\"serei\",\"será\",\"seremos\",\"serão\",\"seria\",\"seríamos\",\"seriam\",\"tenho\",\"tem\",\"temos\",\"tém\",\"tinha\",\"tínhamos\",\"tinham\",\"tive\",\"teve\",\"tivemos\",\"tiveram\",\"tivera\",\"tivéramos\",\"tenha\",\"tenhamos\",\"tenham\",\"tivesse\",\"tivéssemos\",\"tivesse\",\"tiver\",\"tivermos\",\"tiverem\",\"terei\",\"terá\",\"teremos\",\"terão\",\"teria\",\"teríamos\",\"teriam\",\"Se\",\"RT\",\"se\",\"ao\"]\n",
    "\n",
    "text = \" \".join(i for i in df_merge_inner.text)\n",
    "\n",
    "stop_words = Lista_palavras + list(STOPWORDS)\n",
    "\n",
    "regex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\" \n",
    "        u\"\\U0001F300-\\U0001F5FF\"  \n",
    "        u\"\\U0001F680-\\U0001F6FF\"  \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "\n",
    "text_limpo_a = re.sub(regex_pattern,'',text) \n",
    "re_list = ['@[A-Za-z0–9_]+', '#']\n",
    "combined_re = re.compile( '|'.join( re_list) )\n",
    "text_limpo_b = re.sub(combined_re,'',text_limpo_a)\n",
    "\n",
    "wordcloud = WordCloud(max_words=100, collocation_threshold = 10, width = 1500, height = 1000, random_state = 42, collocations = False, colormap = 'tab10', stopwords = stop_words, background_color=\"white\").generate(text_limpo_b)\n",
    "\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_01_sub1_wordcloud.png\", format='png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68b80ae",
   "metadata": {},
   "source": [
    "Gráfico de Interpolação de Centralidades - Modularidade 1 / Modularidade 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_centralidade_inbound = df_a.query('indegree > 0 & modularity_class == @modularidade')[['Id','eigencentrality', 'pageranks', 'Authority', 'weighted indegree']]\n",
    "df_a_centralidade_inbound = df_a_centralidade_inbound.sort_values(['weighted indegree'], ascending=[False])\n",
    "\n",
    "z = df_a_centralidade_inbound['eigencentrality']\n",
    "x = df_a_centralidade_inbound['pageranks']\n",
    "y = df_a_centralidade_inbound['Authority']\n",
    " \n",
    "fig = plt.figure(figsize = (10, 8))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "   \n",
    "ax.grid( color ='grey', \n",
    "        linestyle ='-.', linewidth = 0.3, \n",
    "        alpha = 0.2) \n",
    " \n",
    " \n",
    "my_cmap = plt.get_cmap('hsv')\n",
    " \n",
    "sctt = ax.scatter3D(x, y, z,\n",
    "                    alpha = 0.8,\n",
    "                    c = (x + y + z), \n",
    "                    s =100,\n",
    "                    cmap = my_cmap, \n",
    "                    marker ='o')\n",
    " \n",
    "plt.title(\"Centralidades aplicadas aos Nodes - Modularidade\")\n",
    "ax.set_xlabel('pageranks', fontweight ='bold') \n",
    "ax.set_ylabel('Authority', fontweight ='bold') \n",
    "ax.set_zlabel('eigencentrality', fontweight ='bold')\n",
    "#fig.colorbar(sctt, ax = ax, shrink = 0.5, aspect = 5)\n",
    "plt.margins(0.2)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_01_sub1_centralidade.png\", format='png')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8005d6",
   "metadata": {},
   "source": [
    "Tabela das 10 contas com maior grau de Centralidade de Entrada - Modularidade 1 / Modularidade 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd83e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['Id']=df_c['Id'].str.lower()\n",
    "df_a_centralidade_inbound['Id']=df_a_centralidade_inbound['Id'].str.lower()\n",
    "\n",
    "df_a_centralidade_inbound_classificado = df_a_centralidade_inbound.merge(df_c, on='Id', how='left')\n",
    "df_a_centralidade_inbound_classificado.head(11)\n",
    "\n",
    "\n",
    "dfi.export(\n",
    "    df_a_centralidade_inbound_classificado.head(11),\n",
    "    save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_01_sub1_Tabela_Centralidade.png\",\n",
    "    max_rows = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab52cad",
   "metadata": {},
   "source": [
    "Identificação dos Grupos de Mensagens ligadas as contas indentificadas com os 3 maiores graus de centralidade de entrada - Modularidade 1 / Modularidade 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9801102",
   "metadata": {},
   "outputs": [],
   "source": [
    "nro_outliners = df_a_centralidade_inbound_classificado.head(3)\n",
    "nro_outliners.rename(columns = {'Id':'mention_username'}, inplace = True)\n",
    "col_one_list = nro_outliners['mention_username'].tolist()\n",
    "\n",
    "for indice in col_one_list:\n",
    "    df_b_trab1 = df_b.query('mention_username == @indice')[['author_id', 'mention_username', 'referenced_tweets']]\n",
    "    aux = df_b_trab1['referenced_tweets'].unique()\n",
    "    #print(aux)\n",
    "        \n",
    "    for xx in aux:\n",
    "        # print(xx)\n",
    "        id_tweet_mencao = re.findall('[0-9]+', str(xx))\n",
    "        if id_tweet_mencao != []:\n",
    "            #print(id_tweet_mencao)\n",
    "            retorno_tweet = client.get_tweets(ids=id_tweet_mencao, tweet_fields=['author_id','context_annotations','created_at','geo'])\n",
    "            print(retorno_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e5c66a",
   "metadata": {},
   "source": [
    "Carga dos dados - Modularidade 1 / Modularidade 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4174d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv(arq_contas_brasil, sep=';', low_memory = False, index_col=False)\n",
    "\n",
    "modularidade = mod_02            \n",
    "\n",
    "df_a = pd.read_csv(arq_gephi_mod1, low_memory = False, index_col=False)\n",
    "df_b = pd.read_csv(arq_fonte, low_memory = False, index_col=False)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb971d6",
   "metadata": {},
   "source": [
    "Adequação dos dados - Modularidade 1 / Modularidade 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ee900",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_trab = pd.DataFrame(df_a, columns = [\"Id\", \"modularity_class\"]) \n",
    "df_a_trab = df_a_trab.query('modularity_class == @modularidade')[['Id', 'modularity_class']]\n",
    "df_a_trab['Id_convert'] = df_a_trab['Id'].astype(str)\n",
    "df_b_trab = pd.DataFrame(df_b, columns = [\"author_id\", \"text\"]) \n",
    "df_b_trab['Id_convert'] = df_b_trab['author_id'].astype(str)\n",
    "df_b_trab.rename(columns = {'author_id':'Id'}, inplace = True)\n",
    "df_merge_inner = pd.merge(df_a_trab, df_b_trab, how = 'inner', on = 'Id_convert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d1c035",
   "metadata": {},
   "source": [
    "Nuvem de Palavras - Modularidade 1 / Modularidade 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cadf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lista_palavras = [\"vai\",\"agora\",\"HTTPS\",\"Se\", \"O\", \"ao\",\"de\",\"a\",\"o\",\"que\",\"e\",\"do\",\"da\",\"em\",\"um\",\"para\",\"é\",\"com\",\"não\",\"uma\",\"os\",\"no\",\"se\",\"na\",\"por\",\"mais\",\"as\",\"dos\",\"como\",\"mas\",\"foi\",\"ao\",\"ele\",\"das\",\"tem\",\"à\",\"seu\",\"sua\",\"ou\",\"ser\",\"quando\",\"muito\",\"há\",\"nos\",\"já\",\"está\",\"eu\",\"também\",\"só\",\"pelo\",\"pela\",\"até\",\"isso\",\"ela\",\"entre\",\"era\",\"depois\",\"sem\",\"mesmo\",\"aos\",\"ter\",\"seus\",\"quem\",\"nas\",\"me\",\"esse\",\"eles\",\"estão\",\"você\",\"tinha\",\"foram\",\"essa\",\"num\",\"nem\",\"suas\",\"meu\",\"às\",\"minha\",\"têm\",\"numa\",\"pelos\",\"elas\",\"havia\",\"seja\",\"qual\",\"será\",\"nós\",\"tenho\",\"lhe\",\"deles\",\"essas\",\"esses\",\"pelas\",\"este\",\"fosse\",\"dele\",\"tu\",\"te\",\"vocês\",\"vos\",\"lhes\",\"meus\",\"minhas\",\"teu\",\"tua\",\"teus\",\"tuas\",\"nosso\",\"nossa\",\"nossos\",\"nossas\",\"dela\",\"delas\",\"esta\",\"estes\",\"estas\",\"aquele\",\"aquela\",\"aqueles\",\"aquelas\",\"isto\",\"aquilo\",\"estou\",\"está\",\"estamos\",\"estão\",\"estive\",\"esteve\",\"estivemos\",\"estiveram\",\"estava\",\"estávamos\",\"estavam\",\"estivera\",\"estivéramos\",\"esteja\",\"estejamos\",\"estejam\",\"estivesse\",\"estivéssemos\",\"estivessem\",\"estiver\",\"estivermos\",\"estiverem\",\"hei\",\"há\",\"havemos\",\"hão\",\"houve\",\"houvemos\",\"houveram\",\"houvera\",\"houvéramos\",\"haja\",\"hajamos\",\"hajam\",\"houvesse\",\"houvéssemos\",\"houvessem\",\"houver\",\"houvermos\",\"houverem\",\"houverei\",\"houverá\",\"houveremos\",\"houverão\",\"houveria\",\"houveríamos\",\"houveriam\",\"sou\",\"somos\",\"são\",\"era\",\"éramos\",\"eram\",\"fui\",\"foi\",\"fomos\",\"foram\",\"fora\",\"fôramos\",\"seja\",\"sejamos\",\"sejam\",\"fosse\",\"fôssemos\",\"fossem\",\"for\",\"formos\",\"forem\",\"serei\",\"será\",\"seremos\",\"serão\",\"seria\",\"seríamos\",\"seriam\",\"tenho\",\"tem\",\"temos\",\"tém\",\"tinha\",\"tínhamos\",\"tinham\",\"tive\",\"teve\",\"tivemos\",\"tiveram\",\"tivera\",\"tivéramos\",\"tenha\",\"tenhamos\",\"tenham\",\"tivesse\",\"tivéssemos\",\"tivesse\",\"tiver\",\"tivermos\",\"tiverem\",\"terei\",\"terá\",\"teremos\",\"terão\",\"teria\",\"teríamos\",\"teriam\",\"Se\",\"RT\",\"se\",\"ao\"]\n",
    "\n",
    "text = \" \".join(i for i in df_merge_inner.text)\n",
    "\n",
    "stop_words = Lista_palavras + list(STOPWORDS)\n",
    "\n",
    "regex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  \n",
    "        u\"\\U0001F300-\\U0001F5FF\"  \n",
    "        u\"\\U0001F680-\\U0001F6FF\"  \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\" \n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "\n",
    "text_limpo_a = re.sub(regex_pattern,'',text)\n",
    "\n",
    "re_list = ['@[A-Za-z0–9_]+', '#']\n",
    "combined_re = re.compile( '|'.join( re_list) )\n",
    "text_limpo_b = re.sub(combined_re,'',text_limpo_a)\n",
    "\n",
    "wordcloud = WordCloud(max_words=100, collocation_threshold = 10, width = 1500, height = 1000, random_state = 42, collocations = False, colormap = 'tab10', stopwords = stop_words, background_color=\"white\").generate(text_limpo_b)\n",
    "\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_01_sub2_wordcloud.png\", format='png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7473f6",
   "metadata": {},
   "source": [
    "Gráfico de Interpolação de Centralidades - Modularidade 1 / Modularidade 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f85a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_centralidade_inbound = df_a.query('indegree > 0 & modularity_class == @modularidade')[['Id','eigencentrality', 'pageranks', 'Authority', 'weighted indegree']]\n",
    "df_a_centralidade_inbound = df_a_centralidade_inbound.sort_values(['weighted indegree'], ascending=[False])\n",
    "\n",
    "z = df_a_centralidade_inbound['eigencentrality']\n",
    "x = df_a_centralidade_inbound['pageranks']\n",
    "y = df_a_centralidade_inbound['Authority']\n",
    " \n",
    "fig = plt.figure(figsize = (10, 8))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "   \n",
    "ax.grid( color ='grey', \n",
    "        linestyle ='-.', linewidth = 0.3, \n",
    "        alpha = 0.2) \n",
    " \n",
    " \n",
    "my_cmap = plt.get_cmap('hsv')\n",
    " \n",
    "sctt = ax.scatter3D(x, y, z,\n",
    "                    alpha = 0.8,\n",
    "                    c = (x + y + z), \n",
    "                    s =100,\n",
    "                    cmap = my_cmap, \n",
    "                    marker ='o')\n",
    " \n",
    "plt.title(\"Centralidades aplicadas aos Nodes - Modularidade\")\n",
    "ax.set_xlabel('pageranks', fontweight ='bold') \n",
    "ax.set_ylabel('Authority', fontweight ='bold') \n",
    "ax.set_zlabel('eigencentrality', fontweight ='bold')\n",
    "#fig.colorbar(sctt, ax = ax, shrink = 0.5, aspect = 5)\n",
    "plt.margins(0.2)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_01_sub2_centralidade.png\", format='png')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63ad96",
   "metadata": {},
   "source": [
    "Tabela das 10 contas com maior grau de Centralidade de Entrada - Modularidade 1 / Modularidade 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['Id']=df_c['Id'].str.lower()\n",
    "df_a_centralidade_inbound['Id']=df_a_centralidade_inbound['Id'].str.lower()\n",
    "\n",
    "df_a_centralidade_inbound_classificado = df_a_centralidade_inbound.merge(df_c, on='Id', how='left')\n",
    "df_a_centralidade_inbound_classificado.head(11)\n",
    "\n",
    "dfi.export(\n",
    "    df_a_centralidade_inbound_classificado.head(11),\n",
    "    save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_01_sub2_Tabela_Centralidade.png\",\n",
    "    max_rows = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a0b4de",
   "metadata": {},
   "source": [
    "Identificação dos Grupos de Mensagens ligadas as contas indentificadas com os 3 maiores graus de centralidade de entrada - Modularidade 1 / Modularidade 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e1666",
   "metadata": {},
   "outputs": [],
   "source": [
    "nro_outliners = df_a_centralidade_inbound_classificado.head(3)\n",
    "nro_outliners.rename(columns = {'Id':'mention_username'}, inplace = True)\n",
    "col_one_list = nro_outliners['mention_username'].tolist()\n",
    "\n",
    "for indice in col_one_list:\n",
    "    df_b_trab1 = df_b.query('mention_username == @indice')[['author_id', 'mention_username', 'referenced_tweets']]\n",
    "    aux = df_b_trab1['referenced_tweets'].unique()\n",
    "    #print(aux)\n",
    "        \n",
    "    for xx in aux:\n",
    "        # print(xx)\n",
    "        id_tweet_mencao = re.findall('[0-9]+', str(xx))\n",
    "        if id_tweet_mencao != []:\n",
    "            #print(id_tweet_mencao)\n",
    "            retorno_tweet = client.get_tweets(ids=id_tweet_mencao, tweet_fields=['author_id','context_annotations','created_at','geo'])\n",
    "            print(retorno_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bb0630",
   "metadata": {},
   "source": [
    "Carga dos dados - Modularidade 1 / Modularidade 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7e8b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_c = pd.read_csv(arq_contas_brasil, sep=';', low_memory = False, index_col=False)\n",
    "\n",
    "modularidade = mod_03            \n",
    "\n",
    "df_a = pd.read_csv(arq_gephi_mod1, low_memory = False, index_col=False)\n",
    "df_b = pd.read_csv(arq_fonte, low_memory = False, index_col=False)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295dc21c",
   "metadata": {},
   "source": [
    "Adequação dos dados - Modularidade 1 / Modularidade 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c9553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_trab = pd.DataFrame(df_a, columns = [\"Id\", \"modularity_class\"]) \n",
    "df_a_trab = df_a_trab.query('modularity_class == @modularidade')[['Id', 'modularity_class']]\n",
    "df_a_trab['Id_convert'] = df_a_trab['Id'].astype(str)\n",
    "df_b_trab = pd.DataFrame(df_b, columns = [\"author_id\", \"text\"]) \n",
    "df_b_trab['Id_convert'] = df_b_trab['author_id'].astype(str)\n",
    "df_b_trab.rename(columns = {'author_id':'Id'}, inplace = True)\n",
    "df_merge_inner = pd.merge(df_a_trab, df_b_trab, how = 'inner', on = 'Id_convert')\n",
    "df_merge_inner.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5761648",
   "metadata": {},
   "source": [
    "Nuvem de Palavras - Modularidade 1 / Modularidade 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7250a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lista_palavras = [\"vai\",\"agora\",\"HTTPS\",\"Se\", \"O\", \"ao\",\"de\",\"a\",\"o\",\"que\",\"e\",\"do\",\"da\",\"em\",\"um\",\"para\",\"é\",\"com\",\"não\",\"uma\",\"os\",\"no\",\"se\",\"na\",\"por\",\"mais\",\"as\",\"dos\",\"como\",\"mas\",\"foi\",\"ao\",\"ele\",\"das\",\"tem\",\"à\",\"seu\",\"sua\",\"ou\",\"ser\",\"quando\",\"muito\",\"há\",\"nos\",\"já\",\"está\",\"eu\",\"também\",\"só\",\"pelo\",\"pela\",\"até\",\"isso\",\"ela\",\"entre\",\"era\",\"depois\",\"sem\",\"mesmo\",\"aos\",\"ter\",\"seus\",\"quem\",\"nas\",\"me\",\"esse\",\"eles\",\"estão\",\"você\",\"tinha\",\"foram\",\"essa\",\"num\",\"nem\",\"suas\",\"meu\",\"às\",\"minha\",\"têm\",\"numa\",\"pelos\",\"elas\",\"havia\",\"seja\",\"qual\",\"será\",\"nós\",\"tenho\",\"lhe\",\"deles\",\"essas\",\"esses\",\"pelas\",\"este\",\"fosse\",\"dele\",\"tu\",\"te\",\"vocês\",\"vos\",\"lhes\",\"meus\",\"minhas\",\"teu\",\"tua\",\"teus\",\"tuas\",\"nosso\",\"nossa\",\"nossos\",\"nossas\",\"dela\",\"delas\",\"esta\",\"estes\",\"estas\",\"aquele\",\"aquela\",\"aqueles\",\"aquelas\",\"isto\",\"aquilo\",\"estou\",\"está\",\"estamos\",\"estão\",\"estive\",\"esteve\",\"estivemos\",\"estiveram\",\"estava\",\"estávamos\",\"estavam\",\"estivera\",\"estivéramos\",\"esteja\",\"estejamos\",\"estejam\",\"estivesse\",\"estivéssemos\",\"estivessem\",\"estiver\",\"estivermos\",\"estiverem\",\"hei\",\"há\",\"havemos\",\"hão\",\"houve\",\"houvemos\",\"houveram\",\"houvera\",\"houvéramos\",\"haja\",\"hajamos\",\"hajam\",\"houvesse\",\"houvéssemos\",\"houvessem\",\"houver\",\"houvermos\",\"houverem\",\"houverei\",\"houverá\",\"houveremos\",\"houverão\",\"houveria\",\"houveríamos\",\"houveriam\",\"sou\",\"somos\",\"são\",\"era\",\"éramos\",\"eram\",\"fui\",\"foi\",\"fomos\",\"foram\",\"fora\",\"fôramos\",\"seja\",\"sejamos\",\"sejam\",\"fosse\",\"fôssemos\",\"fossem\",\"for\",\"formos\",\"forem\",\"serei\",\"será\",\"seremos\",\"serão\",\"seria\",\"seríamos\",\"seriam\",\"tenho\",\"tem\",\"temos\",\"tém\",\"tinha\",\"tínhamos\",\"tinham\",\"tive\",\"teve\",\"tivemos\",\"tiveram\",\"tivera\",\"tivéramos\",\"tenha\",\"tenhamos\",\"tenham\",\"tivesse\",\"tivéssemos\",\"tivesse\",\"tiver\",\"tivermos\",\"tiverem\",\"terei\",\"terá\",\"teremos\",\"terão\",\"teria\",\"teríamos\",\"teriam\",\"Se\",\"RT\",\"se\",\"ao\"]\n",
    "\n",
    "text = \" \".join(i for i in df_merge_inner.text)\n",
    "\n",
    "stop_words = Lista_palavras + list(STOPWORDS)\n",
    "\n",
    "regex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  \n",
    "        u\"\\U0001F300-\\U0001F5FF\"  \n",
    "        u\"\\U0001F680-\\U0001F6FF\" \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\" \n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "\n",
    "text_limpo_a = re.sub(regex_pattern,'',text) \n",
    "\n",
    "re_list = ['@[A-Za-z0–9_]+', '#']\n",
    "combined_re = re.compile( '|'.join( re_list) )\n",
    "text_limpo_b = re.sub(combined_re,'',text_limpo_a)\n",
    "\n",
    "wordcloud = WordCloud(max_words=100, collocation_threshold = 10, width = 1500, height = 1000, random_state = 42, collocations = False, colormap = 'tab10', stopwords = stop_words, background_color=\"white\").generate(text_limpo_b)\n",
    "\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_01_sub3_wordcloud.png\", format='png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6fda12",
   "metadata": {},
   "source": [
    "Gráfico de Interpolação de Centralidades - Modularidade 1 / Modularidade 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5afaf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_centralidade_inbound = df_a.query('indegree > 0 & modularity_class == @modularidade')[['Id','eigencentrality', 'pageranks', 'Authority', 'weighted indegree']]\n",
    "df_a_centralidade_inbound = df_a_centralidade_inbound.sort_values(['weighted indegree'], ascending=[False])\n",
    "\n",
    "z = df_a_centralidade_inbound['eigencentrality']\n",
    "x = df_a_centralidade_inbound['pageranks']\n",
    "y = df_a_centralidade_inbound['Authority']\n",
    " \n",
    "fig = plt.figure(figsize = (10, 8))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "   \n",
    "ax.grid( color ='grey', \n",
    "        linestyle ='-.', linewidth = 0.3, \n",
    "        alpha = 0.2) \n",
    " \n",
    " \n",
    "my_cmap = plt.get_cmap('hsv')\n",
    " \n",
    "sctt = ax.scatter3D(x, y, z,\n",
    "                    alpha = 0.8,\n",
    "                    c = (x + y + z), \n",
    "                    s =100,\n",
    "                    cmap = my_cmap, \n",
    "                    marker ='o')\n",
    " \n",
    "plt.title(\"Centralidades aplicadas aos Nodes - Modularidade\")\n",
    "ax.set_xlabel('pageranks', fontweight ='bold') \n",
    "ax.set_ylabel('Authority', fontweight ='bold') \n",
    "ax.set_zlabel('eigencentrality', fontweight ='bold')\n",
    "#fig.colorbar(sctt, ax = ax, shrink = 0.5, aspect = 5)\n",
    "plt.margins(0.2)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_01_sub3_centralidade.png\", format='png')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d84796e",
   "metadata": {},
   "source": [
    "Tabela das 10 contas com maior grau de Centralidade de Entrada - Modularidade 1 / Modularidade 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc46de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['Id']=df_c['Id'].str.lower()\n",
    "df_a_centralidade_inbound['Id']=df_a_centralidade_inbound['Id'].str.lower()\n",
    "\n",
    "df_a_centralidade_inbound_classificado = df_a_centralidade_inbound.merge(df_c, on='Id', how='left')\n",
    "df_a_centralidade_inbound_classificado.head(11)\n",
    "\n",
    "dfi.export(\n",
    "    df_a_centralidade_inbound_classificado.head(11),\n",
    "    save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_01_sub3_Tabela_Centralidade.png\",\n",
    "    max_rows = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d7e14b",
   "metadata": {},
   "source": [
    "Identificação dos Grupos de Mensagens ligadas as contas indentificadas com os 3 maiores graus de centralidade de entrada - Modularidade 1 / Modularidade 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50add8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nro_outliners = df_a_centralidade_inbound_classificado.head(3)\n",
    "nro_outliners.rename(columns = {'Id':'mention_username'}, inplace = True)\n",
    "col_one_list = nro_outliners['mention_username'].tolist()\n",
    "\n",
    "for indice in col_one_list:\n",
    "    df_b_trab1 = df_b.query('mention_username == @indice')[['author_id', 'mention_username', 'referenced_tweets']]\n",
    "    aux = df_b_trab1['referenced_tweets'].unique()\n",
    "    #print(aux)\n",
    "        \n",
    "    for xx in aux:\n",
    "        # print(xx)\n",
    "        id_tweet_mencao = re.findall('[0-9]+', str(xx))\n",
    "        if id_tweet_mencao != []:\n",
    "            #print(id_tweet_mencao)\n",
    "            retorno_tweet = client.get_tweets(ids=id_tweet_mencao, tweet_fields=['author_id','context_annotations','created_at','geo'])\n",
    "            print(retorno_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d2821",
   "metadata": {},
   "source": [
    "Carga dos dados - Modularidade 1 / Modularidade 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bb369af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv(arq_contas_brasil, sep=';', low_memory = False, index_col=False)\n",
    "\n",
    "modularidade = mod_04            \n",
    "\n",
    "df_a = pd.read_csv(arq_gephi_mod1, low_memory = False, index_col=False)\n",
    "df_b = pd.read_csv(arq_fonte, low_memory = False, index_col=False)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c3358b",
   "metadata": {},
   "source": [
    "Adequação dos dados - Modularidade 1 / Modularidade 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_trab = pd.DataFrame(df_a, columns = [\"Id\", \"modularity_class\"]) \n",
    "df_a_trab = df_a_trab.query('modularity_class == @modularidade')[['Id', 'modularity_class']]\n",
    "df_a_trab['Id_convert'] = df_a_trab['Id'].astype(str)\n",
    "df_b_trab = pd.DataFrame(df_b, columns = [\"author_id\", \"text\"]) \n",
    "df_b_trab['Id_convert'] = df_b_trab['author_id'].astype(str)\n",
    "df_b_trab.rename(columns = {'author_id':'Id'}, inplace = True)\n",
    "df_merge_inner = pd.merge(df_a_trab, df_b_trab, how = 'inner', on = 'Id_convert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b365d",
   "metadata": {},
   "source": [
    "Nuvem de Palavras - Modularidade 1 / Modularidade 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lista_palavras = [\"vai\",\"agora\",\"HTTPS\",\"Se\", \"O\", \"ao\",\"de\",\"a\",\"o\",\"que\",\"e\",\"do\",\"da\",\"em\",\"um\",\"para\",\"é\",\"com\",\"não\",\"uma\",\"os\",\"no\",\"se\",\"na\",\"por\",\"mais\",\"as\",\"dos\",\"como\",\"mas\",\"foi\",\"ao\",\"ele\",\"das\",\"tem\",\"à\",\"seu\",\"sua\",\"ou\",\"ser\",\"quando\",\"muito\",\"há\",\"nos\",\"já\",\"está\",\"eu\",\"também\",\"só\",\"pelo\",\"pela\",\"até\",\"isso\",\"ela\",\"entre\",\"era\",\"depois\",\"sem\",\"mesmo\",\"aos\",\"ter\",\"seus\",\"quem\",\"nas\",\"me\",\"esse\",\"eles\",\"estão\",\"você\",\"tinha\",\"foram\",\"essa\",\"num\",\"nem\",\"suas\",\"meu\",\"às\",\"minha\",\"têm\",\"numa\",\"pelos\",\"elas\",\"havia\",\"seja\",\"qual\",\"será\",\"nós\",\"tenho\",\"lhe\",\"deles\",\"essas\",\"esses\",\"pelas\",\"este\",\"fosse\",\"dele\",\"tu\",\"te\",\"vocês\",\"vos\",\"lhes\",\"meus\",\"minhas\",\"teu\",\"tua\",\"teus\",\"tuas\",\"nosso\",\"nossa\",\"nossos\",\"nossas\",\"dela\",\"delas\",\"esta\",\"estes\",\"estas\",\"aquele\",\"aquela\",\"aqueles\",\"aquelas\",\"isto\",\"aquilo\",\"estou\",\"está\",\"estamos\",\"estão\",\"estive\",\"esteve\",\"estivemos\",\"estiveram\",\"estava\",\"estávamos\",\"estavam\",\"estivera\",\"estivéramos\",\"esteja\",\"estejamos\",\"estejam\",\"estivesse\",\"estivéssemos\",\"estivessem\",\"estiver\",\"estivermos\",\"estiverem\",\"hei\",\"há\",\"havemos\",\"hão\",\"houve\",\"houvemos\",\"houveram\",\"houvera\",\"houvéramos\",\"haja\",\"hajamos\",\"hajam\",\"houvesse\",\"houvéssemos\",\"houvessem\",\"houver\",\"houvermos\",\"houverem\",\"houverei\",\"houverá\",\"houveremos\",\"houverão\",\"houveria\",\"houveríamos\",\"houveriam\",\"sou\",\"somos\",\"são\",\"era\",\"éramos\",\"eram\",\"fui\",\"foi\",\"fomos\",\"foram\",\"fora\",\"fôramos\",\"seja\",\"sejamos\",\"sejam\",\"fosse\",\"fôssemos\",\"fossem\",\"for\",\"formos\",\"forem\",\"serei\",\"será\",\"seremos\",\"serão\",\"seria\",\"seríamos\",\"seriam\",\"tenho\",\"tem\",\"temos\",\"tém\",\"tinha\",\"tínhamos\",\"tinham\",\"tive\",\"teve\",\"tivemos\",\"tiveram\",\"tivera\",\"tivéramos\",\"tenha\",\"tenhamos\",\"tenham\",\"tivesse\",\"tivéssemos\",\"tivesse\",\"tiver\",\"tivermos\",\"tiverem\",\"terei\",\"terá\",\"teremos\",\"terão\",\"teria\",\"teríamos\",\"teriam\",\"Se\",\"RT\",\"se\",\"ao\"]\n",
    "\n",
    "\n",
    "text = \" \".join(i for i in df_merge_inner.text)\n",
    "\n",
    "stop_words = Lista_palavras + list(STOPWORDS)\n",
    "\n",
    "regex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  \n",
    "        u\"\\U0001F300-\\U0001F5FF\"  \n",
    "        u\"\\U0001F680-\\U0001F6FF\"  \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "\n",
    "text_limpo_a = re.sub(regex_pattern,'',text) #replaces pattern with ''\n",
    "\n",
    "re_list = ['@[A-Za-z0–9_]+', '#']\n",
    "combined_re = re.compile( '|'.join( re_list) )\n",
    "text_limpo_b = re.sub(combined_re,'',text_limpo_a)\n",
    "\n",
    "wordcloud = WordCloud(max_words=100, collocation_threshold = 10, width = 1500, height = 1000, random_state = 42, collocations = False, colormap = 'tab10', stopwords = stop_words, background_color=\"white\").generate(text_limpo_b)\n",
    "\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_01_sub4_wordcloud.png\", format='png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a11702e",
   "metadata": {},
   "source": [
    "Gráfico de Interpolação de Centralidades - Modularidade 1 / Modularidade 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c4c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_centralidade_inbound = df_a.query('indegree > 0 & modularity_class == @modularidade')[['Id','eigencentrality', 'pageranks', 'Authority', 'weighted indegree']]\n",
    "df_a_centralidade_inbound = df_a_centralidade_inbound.sort_values(['weighted indegree'], ascending=[False])\n",
    "\n",
    "z = df_a_centralidade_inbound['eigencentrality']\n",
    "x = df_a_centralidade_inbound['pageranks']\n",
    "y = df_a_centralidade_inbound['Authority']\n",
    " \n",
    "fig = plt.figure(figsize = (10, 8))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "   \n",
    "ax.grid( color ='grey', \n",
    "        linestyle ='-.', linewidth = 0.3, \n",
    "        alpha = 0.2) \n",
    " \n",
    " \n",
    "my_cmap = plt.get_cmap('hsv')\n",
    " \n",
    "sctt = ax.scatter3D(x, y, z,\n",
    "                    alpha = 0.8,\n",
    "                    c = (x + y + z), \n",
    "                    s =100,\n",
    "                    cmap = my_cmap, \n",
    "                    marker ='o')\n",
    " \n",
    "plt.title(\"Centralidades aplicadas aos Nodes - Modularidade\")\n",
    "ax.set_xlabel('pageranks', fontweight ='bold') \n",
    "ax.set_ylabel('Authority', fontweight ='bold') \n",
    "ax.set_zlabel('eigencentrality', fontweight ='bold')\n",
    "#fig.colorbar(sctt, ax = ax, shrink = 0.5, aspect = 5)\n",
    "plt.margins(0.2)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_01_sub4_centralidade.png\", format='png')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9466035",
   "metadata": {},
   "source": [
    "Tabela das 10 contas com maior grau de Centralidade de Entrada - Modularidade 1 / Modularidade 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ac45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['Id']=df_c['Id'].str.lower()\n",
    "df_a_centralidade_inbound['Id']=df_a_centralidade_inbound['Id'].str.lower()\n",
    "\n",
    "df_a_centralidade_inbound_classificado = df_a_centralidade_inbound.merge(df_c, on='Id', how='left')\n",
    "df_a_centralidade_inbound_classificado.head(11)\n",
    "\n",
    "dfi.export(\n",
    "    df_a_centralidade_inbound_classificado.head(11),\n",
    "    save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_01_sub4_Tabela_Centralidade.png\",\n",
    "    max_rows = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87707de3",
   "metadata": {},
   "source": [
    "Identificação dos Grupos de Mensagens ligadas as contas indentificadas com os 3 maiores graus de centralidade de entrada - Modularidade 1 / Modularidade 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2f6035",
   "metadata": {},
   "outputs": [],
   "source": [
    "nro_outliners = df_a_centralidade_inbound_classificado.head(3)\n",
    "nro_outliners.rename(columns = {'Id':'mention_username'}, inplace = True)\n",
    "col_one_list = nro_outliners['mention_username'].tolist()\n",
    "\n",
    "for indice in col_one_list:\n",
    "    df_b_trab1 = df_b.query('mention_username == @indice')[['author_id', 'mention_username', 'referenced_tweets']]\n",
    "    aux = df_b_trab1['referenced_tweets'].unique()\n",
    "    #print(aux)\n",
    "        \n",
    "    for xx in aux:\n",
    "        # print(xx)\n",
    "        id_tweet_mencao = re.findall('[0-9]+', str(xx))\n",
    "        if id_tweet_mencao != []:\n",
    "            #print(id_tweet_mencao)\n",
    "            retorno_tweet = client.get_tweets(ids=id_tweet_mencao, tweet_fields=['author_id','context_annotations','created_at','geo'])\n",
    "            print(retorno_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba5fb3",
   "metadata": {},
   "source": [
    "Carga dos dados - Modularidade 1 / Modularidade 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2928cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv(arq_contas_brasil, sep=';', low_memory = False, index_col=False)\n",
    "\n",
    "modularidade = mod_05            \n",
    "\n",
    "df_a = pd.read_csv(arq_gephi_mod1, low_memory = False, index_col=False)\n",
    "df_b = pd.read_csv(arq_fonte, low_memory = False, index_col=False)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c176541",
   "metadata": {},
   "source": [
    "Adequação dos dados - Modularidade 1 / Modularidade 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac99a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_trab = pd.DataFrame(df_a, columns = [\"Id\", \"modularity_class\"]) \n",
    "df_a_trab = df_a_trab.query('modularity_class == @modularidade')[['Id', 'modularity_class']]\n",
    "df_a_trab['Id_convert'] = df_a_trab['Id'].astype(str)\n",
    "df_b_trab = pd.DataFrame(df_b, columns = [\"author_id\", \"text\"]) \n",
    "df_b_trab['Id_convert'] = df_b_trab['author_id'].astype(str)\n",
    "df_b_trab.rename(columns = {'author_id':'Id'}, inplace = True)\n",
    "df_merge_inner = pd.merge(df_a_trab, df_b_trab, how = 'inner', on = 'Id_convert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bc53b8",
   "metadata": {},
   "source": [
    "Nuvem de Palavras - Modularidade 1 / Modularidade 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lista_palavras = [\"vai\",\"agora\",\"HTTPS\",\"Se\", \"O\", \"ao\",\"de\",\"a\",\"o\",\"que\",\"e\",\"do\",\"da\",\"em\",\"um\",\"para\",\"é\",\"com\",\"não\",\"uma\",\"os\",\"no\",\"se\",\"na\",\"por\",\"mais\",\"as\",\"dos\",\"como\",\"mas\",\"foi\",\"ao\",\"ele\",\"das\",\"tem\",\"à\",\"seu\",\"sua\",\"ou\",\"ser\",\"quando\",\"muito\",\"há\",\"nos\",\"já\",\"está\",\"eu\",\"também\",\"só\",\"pelo\",\"pela\",\"até\",\"isso\",\"ela\",\"entre\",\"era\",\"depois\",\"sem\",\"mesmo\",\"aos\",\"ter\",\"seus\",\"quem\",\"nas\",\"me\",\"esse\",\"eles\",\"estão\",\"você\",\"tinha\",\"foram\",\"essa\",\"num\",\"nem\",\"suas\",\"meu\",\"às\",\"minha\",\"têm\",\"numa\",\"pelos\",\"elas\",\"havia\",\"seja\",\"qual\",\"será\",\"nós\",\"tenho\",\"lhe\",\"deles\",\"essas\",\"esses\",\"pelas\",\"este\",\"fosse\",\"dele\",\"tu\",\"te\",\"vocês\",\"vos\",\"lhes\",\"meus\",\"minhas\",\"teu\",\"tua\",\"teus\",\"tuas\",\"nosso\",\"nossa\",\"nossos\",\"nossas\",\"dela\",\"delas\",\"esta\",\"estes\",\"estas\",\"aquele\",\"aquela\",\"aqueles\",\"aquelas\",\"isto\",\"aquilo\",\"estou\",\"está\",\"estamos\",\"estão\",\"estive\",\"esteve\",\"estivemos\",\"estiveram\",\"estava\",\"estávamos\",\"estavam\",\"estivera\",\"estivéramos\",\"esteja\",\"estejamos\",\"estejam\",\"estivesse\",\"estivéssemos\",\"estivessem\",\"estiver\",\"estivermos\",\"estiverem\",\"hei\",\"há\",\"havemos\",\"hão\",\"houve\",\"houvemos\",\"houveram\",\"houvera\",\"houvéramos\",\"haja\",\"hajamos\",\"hajam\",\"houvesse\",\"houvéssemos\",\"houvessem\",\"houver\",\"houvermos\",\"houverem\",\"houverei\",\"houverá\",\"houveremos\",\"houverão\",\"houveria\",\"houveríamos\",\"houveriam\",\"sou\",\"somos\",\"são\",\"era\",\"éramos\",\"eram\",\"fui\",\"foi\",\"fomos\",\"foram\",\"fora\",\"fôramos\",\"seja\",\"sejamos\",\"sejam\",\"fosse\",\"fôssemos\",\"fossem\",\"for\",\"formos\",\"forem\",\"serei\",\"será\",\"seremos\",\"serão\",\"seria\",\"seríamos\",\"seriam\",\"tenho\",\"tem\",\"temos\",\"tém\",\"tinha\",\"tínhamos\",\"tinham\",\"tive\",\"teve\",\"tivemos\",\"tiveram\",\"tivera\",\"tivéramos\",\"tenha\",\"tenhamos\",\"tenham\",\"tivesse\",\"tivéssemos\",\"tivesse\",\"tiver\",\"tivermos\",\"tiverem\",\"terei\",\"terá\",\"teremos\",\"terão\",\"teria\",\"teríamos\",\"teriam\",\"Se\",\"RT\",\"se\",\"ao\"]\n",
    "\n",
    "\n",
    "text = \" \".join(i for i in df_merge_inner.text)\n",
    "\n",
    "stop_words = Lista_palavras + list(STOPWORDS)\n",
    "\n",
    "regex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\" \n",
    "        u\"\\U0001F300-\\U0001F5FF\" \n",
    "        u\"\\U0001F680-\\U0001F6FF\" \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\" \n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "\n",
    "text_limpo_a = re.sub(regex_pattern,'',text) \n",
    "\n",
    "re_list = ['@[A-Za-z0–9_]+', '#']\n",
    "combined_re = re.compile( '|'.join( re_list) )\n",
    "text_limpo_b = re.sub(combined_re,'',text_limpo_a)\n",
    "\n",
    "wordcloud = WordCloud(max_words=100, collocation_threshold = 10, width = 1500, height = 1000, random_state = 42, collocations = False, colormap = 'tab10', stopwords = stop_words, background_color=\"white\").generate(text_limpo_b)\n",
    "\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_01_sub5_wordcloud.png\", format='png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f37da",
   "metadata": {},
   "source": [
    "Gráfico de Interpolação de Centralidades - Modularidade 1 / Modularidade 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7c5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_centralidade_inbound = df_a.query('indegree > 0 & modularity_class == @modularidade')[['Id','eigencentrality', 'pageranks', 'Authority', 'weighted indegree']]\n",
    "df_a_centralidade_inbound = df_a_centralidade_inbound.sort_values(['weighted indegree'], ascending=[False])\n",
    "\n",
    "z = df_a_centralidade_inbound['eigencentrality']\n",
    "x = df_a_centralidade_inbound['pageranks']\n",
    "y = df_a_centralidade_inbound['Authority']\n",
    " \n",
    "fig = plt.figure(figsize = (10, 8))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "   \n",
    "ax.grid( color ='grey', \n",
    "        linestyle ='-.', linewidth = 0.3, \n",
    "        alpha = 0.2) \n",
    " \n",
    " \n",
    "my_cmap = plt.get_cmap('hsv')\n",
    " \n",
    "sctt = ax.scatter3D(x, y, z,\n",
    "                    alpha = 0.8,\n",
    "                    c = (x + y + z), \n",
    "                    s =100,\n",
    "                    cmap = my_cmap, \n",
    "                    marker ='o')\n",
    " \n",
    "plt.title(\"Centralidades aplicadas aos Nodes - Modularidade\")\n",
    "ax.set_xlabel('pageranks', fontweight ='bold') \n",
    "ax.set_ylabel('Authority', fontweight ='bold') \n",
    "ax.set_zlabel('eigencentrality', fontweight ='bold')\n",
    "#fig.colorbar(sctt, ax = ax, shrink = 0.5, aspect = 5)\n",
    "plt.margins(0.2)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_01_sub5_centralidade.png\", format='png')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc4bcdc",
   "metadata": {},
   "source": [
    "Tabela das 10 contas com maior grau de Centralidade de Entrada - Modularidade 1 / Modularidade 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a82f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['Id']=df_c['Id'].str.lower()\n",
    "df_a_centralidade_inbound['Id']=df_a_centralidade_inbound['Id'].str.lower()\n",
    "\n",
    "df_a_centralidade_inbound_classificado = df_a_centralidade_inbound.merge(df_c, on='Id', how='left')\n",
    "df_a_centralidade_inbound_classificado.head(11)\n",
    "\n",
    "dfi.export(\n",
    "    df_a_centralidade_inbound_classificado.head(11),\n",
    "    save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_01_sub5_Tabela_Centralidade.png\",\n",
    "    max_rows = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff06c5c3",
   "metadata": {},
   "source": [
    "Identificação dos Grupos de Mensagens ligadas as contas indentificadas com os 3 maiores graus de centralidade de entrada - Modularidade 1 / Modularidade 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88a5e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nro_outliners = df_a_centralidade_inbound_classificado.head(3)\n",
    "nro_outliners.rename(columns = {'Id':'mention_username'}, inplace = True)\n",
    "col_one_list = nro_outliners['mention_username'].tolist()\n",
    "\n",
    "for indice in col_one_list:\n",
    "    df_b_trab1 = df_b.query('mention_username == @indice')[['author_id', 'mention_username', 'referenced_tweets']]\n",
    "    aux = df_b_trab1['referenced_tweets'].unique()\n",
    "    #print(aux)\n",
    "        \n",
    "    for xx in aux:\n",
    "        # print(xx)\n",
    "        id_tweet_mencao = re.findall('[0-9]+', str(xx))\n",
    "        if id_tweet_mencao != []:\n",
    "            #print(id_tweet_mencao)\n",
    "            retorno_tweet = client.get_tweets(ids=id_tweet_mencao, tweet_fields=['author_id','context_annotations','created_at','geo'])\n",
    "            print(retorno_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605847a6",
   "metadata": {},
   "source": [
    "Inicio do Estudo da Modularidade 2 - Declaração das 5 maiores modularidades encontradas nesse grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "963e352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_01 = 3\n",
    "mod_02 = 2\n",
    "mod_03 = 1\n",
    "mod_04 = 0\n",
    "mod_05 = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6af181",
   "metadata": {},
   "source": [
    "Carga dos dados - Modularidade 2 \\ Modularidade 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb995cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv(arq_contas_brasil, sep=';', low_memory = False, index_col=False)\n",
    "\n",
    "modularidade = mod_01            \n",
    "\n",
    "df_a = pd.read_csv(arq_gephi_mod2, low_memory = False, index_col=False)\n",
    "df_b = pd.read_csv(arq_fonte, low_memory = False, index_col=False)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f41f0b1",
   "metadata": {},
   "source": [
    "Adequação dos dados - Modularidade 2 \\ Modularidade 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43342a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_trab = pd.DataFrame(df_a, columns = [\"Id\", \"modularity_class\"]) \n",
    "df_a_trab = df_a_trab.query('modularity_class == @modularidade')[['Id', 'modularity_class']]\n",
    "df_a_trab['Id_convert'] = df_a_trab['Id'].astype(str)\n",
    "df_b_trab = pd.DataFrame(df_b, columns = [\"author_id\", \"text\"]) \n",
    "df_b_trab['Id_convert'] = df_b_trab['author_id'].astype(str)\n",
    "df_b_trab.rename(columns = {'author_id':'Id'}, inplace = True)\n",
    "df_merge_inner = pd.merge(df_a_trab, df_b_trab, how = 'inner', on = 'Id_convert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae0043",
   "metadata": {},
   "source": [
    "Nuvem de Palavras - Modularidade 2 \\ Modularidade 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49893549",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lista_palavras = [\"vai\",\"agora\",\"HTTPS\",\"Se\", \"O\", \"ao\",\"de\",\"a\",\"o\",\"que\",\"e\",\"do\",\"da\",\"em\",\"um\",\"para\",\"é\",\"com\",\"não\",\"uma\",\"os\",\"no\",\"se\",\"na\",\"por\",\"mais\",\"as\",\"dos\",\"como\",\"mas\",\"foi\",\"ao\",\"ele\",\"das\",\"tem\",\"à\",\"seu\",\"sua\",\"ou\",\"ser\",\"quando\",\"muito\",\"há\",\"nos\",\"já\",\"está\",\"eu\",\"também\",\"só\",\"pelo\",\"pela\",\"até\",\"isso\",\"ela\",\"entre\",\"era\",\"depois\",\"sem\",\"mesmo\",\"aos\",\"ter\",\"seus\",\"quem\",\"nas\",\"me\",\"esse\",\"eles\",\"estão\",\"você\",\"tinha\",\"foram\",\"essa\",\"num\",\"nem\",\"suas\",\"meu\",\"às\",\"minha\",\"têm\",\"numa\",\"pelos\",\"elas\",\"havia\",\"seja\",\"qual\",\"será\",\"nós\",\"tenho\",\"lhe\",\"deles\",\"essas\",\"esses\",\"pelas\",\"este\",\"fosse\",\"dele\",\"tu\",\"te\",\"vocês\",\"vos\",\"lhes\",\"meus\",\"minhas\",\"teu\",\"tua\",\"teus\",\"tuas\",\"nosso\",\"nossa\",\"nossos\",\"nossas\",\"dela\",\"delas\",\"esta\",\"estes\",\"estas\",\"aquele\",\"aquela\",\"aqueles\",\"aquelas\",\"isto\",\"aquilo\",\"estou\",\"está\",\"estamos\",\"estão\",\"estive\",\"esteve\",\"estivemos\",\"estiveram\",\"estava\",\"estávamos\",\"estavam\",\"estivera\",\"estivéramos\",\"esteja\",\"estejamos\",\"estejam\",\"estivesse\",\"estivéssemos\",\"estivessem\",\"estiver\",\"estivermos\",\"estiverem\",\"hei\",\"há\",\"havemos\",\"hão\",\"houve\",\"houvemos\",\"houveram\",\"houvera\",\"houvéramos\",\"haja\",\"hajamos\",\"hajam\",\"houvesse\",\"houvéssemos\",\"houvessem\",\"houver\",\"houvermos\",\"houverem\",\"houverei\",\"houverá\",\"houveremos\",\"houverão\",\"houveria\",\"houveríamos\",\"houveriam\",\"sou\",\"somos\",\"são\",\"era\",\"éramos\",\"eram\",\"fui\",\"foi\",\"fomos\",\"foram\",\"fora\",\"fôramos\",\"seja\",\"sejamos\",\"sejam\",\"fosse\",\"fôssemos\",\"fossem\",\"for\",\"formos\",\"forem\",\"serei\",\"será\",\"seremos\",\"serão\",\"seria\",\"seríamos\",\"seriam\",\"tenho\",\"tem\",\"temos\",\"tém\",\"tinha\",\"tínhamos\",\"tinham\",\"tive\",\"teve\",\"tivemos\",\"tiveram\",\"tivera\",\"tivéramos\",\"tenha\",\"tenhamos\",\"tenham\",\"tivesse\",\"tivéssemos\",\"tivesse\",\"tiver\",\"tivermos\",\"tiverem\",\"terei\",\"terá\",\"teremos\",\"terão\",\"teria\",\"teríamos\",\"teriam\",\"Se\",\"RT\",\"se\",\"ao\"]\n",
    "\n",
    "text = \" \".join(i for i in df_merge_inner.text)\n",
    "\n",
    "stop_words = Lista_palavras + list(STOPWORDS)\n",
    "\n",
    "regex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\" \n",
    "        u\"\\U0001F300-\\U0001F5FF\"  \n",
    "        u\"\\U0001F680-\\U0001F6FF\"  \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\" \n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "\n",
    "text_limpo_a = re.sub(regex_pattern,'',text)\n",
    "\n",
    "re_list = ['@[A-Za-z0–9_]+', '#']\n",
    "combined_re = re.compile( '|'.join( re_list) )\n",
    "text_limpo_b = re.sub(combined_re,'',text_limpo_a)\n",
    "\n",
    "wordcloud = WordCloud(max_words=100, collocation_threshold = 10, width = 1500, height = 1000, random_state = 42, collocations = False, colormap = 'tab10', stopwords = stop_words, background_color=\"white\").generate(text_limpo_b)\n",
    "\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_02_sub1_wordcloud.png\", format='png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33421cc2",
   "metadata": {},
   "source": [
    "Gráfico de Interpolação de Centralidades - Modularidade 2 \\ Modularidade 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a76745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_centralidade_inbound = df_a.query('indegree > 0 & modularity_class == @modularidade')[['Id','eigencentrality', 'pageranks', 'Authority', 'weighted indegree']]\n",
    "df_a_centralidade_inbound = df_a_centralidade_inbound.sort_values(['weighted indegree'], ascending=[False])\n",
    "\n",
    "z = df_a_centralidade_inbound['eigencentrality']\n",
    "x = df_a_centralidade_inbound['pageranks']\n",
    "y = df_a_centralidade_inbound['Authority']\n",
    " \n",
    "fig = plt.figure(figsize = (10, 8))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "   \n",
    "ax.grid( color ='grey', \n",
    "        linestyle ='-.', linewidth = 0.3, \n",
    "        alpha = 0.2) \n",
    " \n",
    " \n",
    "my_cmap = plt.get_cmap('hsv')\n",
    " \n",
    "sctt = ax.scatter3D(x, y, z,\n",
    "                    alpha = 0.8,\n",
    "                    c = (x + y + z), \n",
    "                    s =100,\n",
    "                    cmap = my_cmap, \n",
    "                    marker ='o')\n",
    " \n",
    "plt.title(\"Centralidades aplicadas aos Nodes - Modularidade\")\n",
    "ax.set_xlabel('pageranks', fontweight ='bold') \n",
    "ax.set_ylabel('Authority', fontweight ='bold') \n",
    "ax.set_zlabel('eigencentrality', fontweight ='bold')\n",
    "#fig.colorbar(sctt, ax = ax, shrink = 0.5, aspect = 5)\n",
    "plt.margins(0.2)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_02_sub1_centralidade.png\", format='png')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15df151c",
   "metadata": {},
   "source": [
    "Tabela das 10 contas com maior grau de Centralidade de Entrada - Modularidade 2 \\ Modularidade 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7286440",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['Id']=df_c['Id'].str.lower()\n",
    "df_a_centralidade_inbound['Id']=df_a_centralidade_inbound['Id'].str.lower()\n",
    "\n",
    "df_a_centralidade_inbound_classificado = df_a_centralidade_inbound.merge(df_c, on='Id', how='left')\n",
    "df_a_centralidade_inbound_classificado.head(11)\n",
    "\n",
    "\n",
    "dfi.export(\n",
    "    df_a_centralidade_inbound_classificado.head(11),\n",
    "    save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_02_sub1_Tabela_Centralidade.png\",\n",
    "    max_rows = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04adb68c",
   "metadata": {},
   "source": [
    "Identificação dos Grupos de Mensagens ligadas as contas indentificadas com os 3 maiores graus de centralidade de entrada - Modularidade 2 \\ Modularidade 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0504d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nro_outliners = df_a_centralidade_inbound_classificado.head(3)\n",
    "nro_outliners.rename(columns = {'Id':'mention_username'}, inplace = True)\n",
    "col_one_list = nro_outliners['mention_username'].tolist()\n",
    "\n",
    "for indice in col_one_list:\n",
    "    df_b_trab1 = df_b.query('mention_username == @indice')[['author_id', 'mention_username', 'referenced_tweets']]\n",
    "    aux = df_b_trab1['referenced_tweets'].unique()\n",
    "    #print(aux)\n",
    "        \n",
    "    for xx in aux:\n",
    "        # print(xx)\n",
    "        id_tweet_mencao = re.findall('[0-9]+', str(xx))\n",
    "        if id_tweet_mencao != []:\n",
    "            #print(id_tweet_mencao)\n",
    "            retorno_tweet = client.get_tweets(ids=id_tweet_mencao, tweet_fields=['author_id','context_annotations','created_at','geo'])\n",
    "            print(retorno_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24169ba",
   "metadata": {},
   "source": [
    "Carga dos dados - Modularidade 2 \\ Modularidade 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0c18565",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv(arq_contas_brasil, sep=';', low_memory = False, index_col=False)\n",
    "\n",
    "modularidade = mod_02            \n",
    "\n",
    "df_a = pd.read_csv(arq_gephi_mod2, low_memory = False, index_col=False)\n",
    "df_b = pd.read_csv(arq_fonte, low_memory = False, index_col=False)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a77daa4",
   "metadata": {},
   "source": [
    "Adequação dos dados - Modularidade 2 \\ Modularidade 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f84c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_trab = pd.DataFrame(df_a, columns = [\"Id\", \"modularity_class\"]) \n",
    "df_a_trab = df_a_trab.query('modularity_class == @modularidade')[['Id', 'modularity_class']]\n",
    "df_a_trab['Id_convert'] = df_a_trab['Id'].astype(str)\n",
    "df_b_trab = pd.DataFrame(df_b, columns = [\"author_id\", \"text\"]) \n",
    "df_b_trab['Id_convert'] = df_b_trab['author_id'].astype(str)\n",
    "df_b_trab.rename(columns = {'author_id':'Id'}, inplace = True)\n",
    "df_merge_inner = pd.merge(df_a_trab, df_b_trab, how = 'inner', on = 'Id_convert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103732fa",
   "metadata": {},
   "source": [
    "Nuvem de Palavras - Modularidade 2 \\ Modularidade 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993cd24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lista_palavras = [\"vai\",\"agora\",\"HTTPS\",\"Se\", \"O\", \"ao\",\"de\",\"a\",\"o\",\"que\",\"e\",\"do\",\"da\",\"em\",\"um\",\"para\",\"é\",\"com\",\"não\",\"uma\",\"os\",\"no\",\"se\",\"na\",\"por\",\"mais\",\"as\",\"dos\",\"como\",\"mas\",\"foi\",\"ao\",\"ele\",\"das\",\"tem\",\"à\",\"seu\",\"sua\",\"ou\",\"ser\",\"quando\",\"muito\",\"há\",\"nos\",\"já\",\"está\",\"eu\",\"também\",\"só\",\"pelo\",\"pela\",\"até\",\"isso\",\"ela\",\"entre\",\"era\",\"depois\",\"sem\",\"mesmo\",\"aos\",\"ter\",\"seus\",\"quem\",\"nas\",\"me\",\"esse\",\"eles\",\"estão\",\"você\",\"tinha\",\"foram\",\"essa\",\"num\",\"nem\",\"suas\",\"meu\",\"às\",\"minha\",\"têm\",\"numa\",\"pelos\",\"elas\",\"havia\",\"seja\",\"qual\",\"será\",\"nós\",\"tenho\",\"lhe\",\"deles\",\"essas\",\"esses\",\"pelas\",\"este\",\"fosse\",\"dele\",\"tu\",\"te\",\"vocês\",\"vos\",\"lhes\",\"meus\",\"minhas\",\"teu\",\"tua\",\"teus\",\"tuas\",\"nosso\",\"nossa\",\"nossos\",\"nossas\",\"dela\",\"delas\",\"esta\",\"estes\",\"estas\",\"aquele\",\"aquela\",\"aqueles\",\"aquelas\",\"isto\",\"aquilo\",\"estou\",\"está\",\"estamos\",\"estão\",\"estive\",\"esteve\",\"estivemos\",\"estiveram\",\"estava\",\"estávamos\",\"estavam\",\"estivera\",\"estivéramos\",\"esteja\",\"estejamos\",\"estejam\",\"estivesse\",\"estivéssemos\",\"estivessem\",\"estiver\",\"estivermos\",\"estiverem\",\"hei\",\"há\",\"havemos\",\"hão\",\"houve\",\"houvemos\",\"houveram\",\"houvera\",\"houvéramos\",\"haja\",\"hajamos\",\"hajam\",\"houvesse\",\"houvéssemos\",\"houvessem\",\"houver\",\"houvermos\",\"houverem\",\"houverei\",\"houverá\",\"houveremos\",\"houverão\",\"houveria\",\"houveríamos\",\"houveriam\",\"sou\",\"somos\",\"são\",\"era\",\"éramos\",\"eram\",\"fui\",\"foi\",\"fomos\",\"foram\",\"fora\",\"fôramos\",\"seja\",\"sejamos\",\"sejam\",\"fosse\",\"fôssemos\",\"fossem\",\"for\",\"formos\",\"forem\",\"serei\",\"será\",\"seremos\",\"serão\",\"seria\",\"seríamos\",\"seriam\",\"tenho\",\"tem\",\"temos\",\"tém\",\"tinha\",\"tínhamos\",\"tinham\",\"tive\",\"teve\",\"tivemos\",\"tiveram\",\"tivera\",\"tivéramos\",\"tenha\",\"tenhamos\",\"tenham\",\"tivesse\",\"tivéssemos\",\"tivesse\",\"tiver\",\"tivermos\",\"tiverem\",\"terei\",\"terá\",\"teremos\",\"terão\",\"teria\",\"teríamos\",\"teriam\",\"Se\",\"RT\",\"se\",\"ao\"]\n",
    "\n",
    "text = \" \".join(i for i in df_merge_inner.text)\n",
    "\n",
    "stop_words = Lista_palavras + list(STOPWORDS)\n",
    "\n",
    "regex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "\n",
    "text_limpo_a = re.sub(regex_pattern,'',text) \n",
    "\n",
    "re_list = ['@[A-Za-z0–9_]+', '#']\n",
    "combined_re = re.compile( '|'.join( re_list) )\n",
    "text_limpo_b = re.sub(combined_re,'',text_limpo_a)\n",
    "\n",
    "wordcloud = WordCloud(max_words=100, collocation_threshold = 10, width = 1500, height = 1000, random_state = 42, collocations = False, colormap = 'tab10', stopwords = stop_words, background_color=\"white\").generate(text_limpo_b)\n",
    "\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_02_sub2_wordcloud.png\", format='png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d5eed4",
   "metadata": {},
   "source": [
    "Gráfico de Interpolação de Centralidades - Modularidade 2 \\ Modularidade 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_centralidade_inbound = df_a.query('indegree > 0 & modularity_class == @modularidade')[['Id','eigencentrality', 'pageranks', 'Authority', 'weighted indegree']]\n",
    "df_a_centralidade_inbound = df_a_centralidade_inbound.sort_values(['weighted indegree'], ascending=[False])\n",
    "\n",
    "z = df_a_centralidade_inbound['eigencentrality']\n",
    "x = df_a_centralidade_inbound['pageranks']\n",
    "y = df_a_centralidade_inbound['Authority']\n",
    " \n",
    "fig = plt.figure(figsize = (10, 8))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "   \n",
    "ax.grid( color ='grey', \n",
    "        linestyle ='-.', linewidth = 0.3, \n",
    "        alpha = 0.2) \n",
    " \n",
    " \n",
    "my_cmap = plt.get_cmap('hsv')\n",
    " \n",
    "sctt = ax.scatter3D(x, y, z,\n",
    "                    alpha = 0.8,\n",
    "                    c = (x + y + z), \n",
    "                    s =100,\n",
    "                    cmap = my_cmap, \n",
    "                    marker ='o')\n",
    " \n",
    "plt.title(\"Centralidades aplicadas aos Nodes - Modularidade\")\n",
    "ax.set_xlabel('pageranks', fontweight ='bold') \n",
    "ax.set_ylabel('Authority', fontweight ='bold') \n",
    "ax.set_zlabel('eigencentrality', fontweight ='bold')\n",
    "#fig.colorbar(sctt, ax = ax, shrink = 0.5, aspect = 5)\n",
    "plt.margins(0.2)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_02_sub2_centralidade.png\", format='png')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb351a1",
   "metadata": {},
   "source": [
    "Tabela das 10 contas com maior grau de Centralidade de Entrada - Modularidade 2 \\ Modularidade 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3dfedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['Id']=df_c['Id'].str.lower()\n",
    "df_a_centralidade_inbound['Id']=df_a_centralidade_inbound['Id'].str.lower()\n",
    "\n",
    "df_a_centralidade_inbound_classificado = df_a_centralidade_inbound.merge(df_c, on='Id', how='left')\n",
    "df_a_centralidade_inbound_classificado.head(11)\n",
    "\n",
    "dfi.export(\n",
    "    df_a_centralidade_inbound_classificado.head(11),\n",
    "    save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_02_sub2_Tabela_Centralidade.png\",\n",
    "    max_rows = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74610c7",
   "metadata": {},
   "source": [
    "Identificação dos Grupos de Mensagens ligadas as contas indentificadas com os 3 maiores graus de centralidade de entrada - Modularidade 2 \\ Modularidade 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d7f07e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nro_outliners = df_a_centralidade_inbound_classificado.head(3)\n",
    "nro_outliners.rename(columns = {'Id':'mention_username'}, inplace = True)\n",
    "col_one_list = nro_outliners['mention_username'].tolist()\n",
    "\n",
    "for indice in col_one_list:\n",
    "    df_b_trab1 = df_b.query('mention_username == @indice')[['author_id', 'mention_username', 'referenced_tweets']]\n",
    "    aux = df_b_trab1['referenced_tweets'].unique()\n",
    "    #print(aux)\n",
    "        \n",
    "    for xx in aux:\n",
    "        # print(xx)\n",
    "        id_tweet_mencao = re.findall('[0-9]+', str(xx))\n",
    "        if id_tweet_mencao != []:\n",
    "            #print(id_tweet_mencao)\n",
    "            retorno_tweet = client.get_tweets(ids=id_tweet_mencao, tweet_fields=['author_id','context_annotations','created_at','geo'])\n",
    "            print(retorno_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bc130c",
   "metadata": {},
   "source": [
    "Carga dos dados - Modularidade 2 \\ Modularidade 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f6dc7952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv(arq_contas_brasil, sep=';', low_memory = False, index_col=False)\n",
    "\n",
    "modularidade = mod_03            \n",
    "\n",
    "df_a = pd.read_csv(arq_gephi_mod2, low_memory = False, index_col=False)\n",
    "df_b = pd.read_csv(arq_fonte, low_memory = False, index_col=False)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d40eb0",
   "metadata": {},
   "source": [
    "Adequação dos dados - Modularidade 2 \\ Modularidade 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8981ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_trab = pd.DataFrame(df_a, columns = [\"Id\", \"modularity_class\"]) \n",
    "df_a_trab = df_a_trab.query('modularity_class == @modularidade')[['Id', 'modularity_class']]\n",
    "df_a_trab['Id_convert'] = df_a_trab['Id'].astype(str)\n",
    "df_b_trab = pd.DataFrame(df_b, columns = [\"author_id\", \"text\"]) \n",
    "df_b_trab['Id_convert'] = df_b_trab['author_id'].astype(str)\n",
    "df_b_trab.rename(columns = {'author_id':'Id'}, inplace = True)\n",
    "df_merge_inner = pd.merge(df_a_trab, df_b_trab, how = 'inner', on = 'Id_convert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1cc4f7",
   "metadata": {},
   "source": [
    "Nuvem de Palavras - Modularidade 2 \\ Modularidade 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55215f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lista_palavras = [\"vai\",\"agora\",\"HTTPS\",\"Se\", \"O\", \"ao\",\"de\",\"a\",\"o\",\"que\",\"e\",\"do\",\"da\",\"em\",\"um\",\"para\",\"é\",\"com\",\"não\",\"uma\",\"os\",\"no\",\"se\",\"na\",\"por\",\"mais\",\"as\",\"dos\",\"como\",\"mas\",\"foi\",\"ao\",\"ele\",\"das\",\"tem\",\"à\",\"seu\",\"sua\",\"ou\",\"ser\",\"quando\",\"muito\",\"há\",\"nos\",\"já\",\"está\",\"eu\",\"também\",\"só\",\"pelo\",\"pela\",\"até\",\"isso\",\"ela\",\"entre\",\"era\",\"depois\",\"sem\",\"mesmo\",\"aos\",\"ter\",\"seus\",\"quem\",\"nas\",\"me\",\"esse\",\"eles\",\"estão\",\"você\",\"tinha\",\"foram\",\"essa\",\"num\",\"nem\",\"suas\",\"meu\",\"às\",\"minha\",\"têm\",\"numa\",\"pelos\",\"elas\",\"havia\",\"seja\",\"qual\",\"será\",\"nós\",\"tenho\",\"lhe\",\"deles\",\"essas\",\"esses\",\"pelas\",\"este\",\"fosse\",\"dele\",\"tu\",\"te\",\"vocês\",\"vos\",\"lhes\",\"meus\",\"minhas\",\"teu\",\"tua\",\"teus\",\"tuas\",\"nosso\",\"nossa\",\"nossos\",\"nossas\",\"dela\",\"delas\",\"esta\",\"estes\",\"estas\",\"aquele\",\"aquela\",\"aqueles\",\"aquelas\",\"isto\",\"aquilo\",\"estou\",\"está\",\"estamos\",\"estão\",\"estive\",\"esteve\",\"estivemos\",\"estiveram\",\"estava\",\"estávamos\",\"estavam\",\"estivera\",\"estivéramos\",\"esteja\",\"estejamos\",\"estejam\",\"estivesse\",\"estivéssemos\",\"estivessem\",\"estiver\",\"estivermos\",\"estiverem\",\"hei\",\"há\",\"havemos\",\"hão\",\"houve\",\"houvemos\",\"houveram\",\"houvera\",\"houvéramos\",\"haja\",\"hajamos\",\"hajam\",\"houvesse\",\"houvéssemos\",\"houvessem\",\"houver\",\"houvermos\",\"houverem\",\"houverei\",\"houverá\",\"houveremos\",\"houverão\",\"houveria\",\"houveríamos\",\"houveriam\",\"sou\",\"somos\",\"são\",\"era\",\"éramos\",\"eram\",\"fui\",\"foi\",\"fomos\",\"foram\",\"fora\",\"fôramos\",\"seja\",\"sejamos\",\"sejam\",\"fosse\",\"fôssemos\",\"fossem\",\"for\",\"formos\",\"forem\",\"serei\",\"será\",\"seremos\",\"serão\",\"seria\",\"seríamos\",\"seriam\",\"tenho\",\"tem\",\"temos\",\"tém\",\"tinha\",\"tínhamos\",\"tinham\",\"tive\",\"teve\",\"tivemos\",\"tiveram\",\"tivera\",\"tivéramos\",\"tenha\",\"tenhamos\",\"tenham\",\"tivesse\",\"tivéssemos\",\"tivesse\",\"tiver\",\"tivermos\",\"tiverem\",\"terei\",\"terá\",\"teremos\",\"terão\",\"teria\",\"teríamos\",\"teriam\",\"Se\",\"RT\",\"se\",\"ao\"]\n",
    "\n",
    "text = \" \".join(i for i in df_merge_inner.text)\n",
    "\n",
    "stop_words = Lista_palavras + list(STOPWORDS)\n",
    "\n",
    "regex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\" \n",
    "        u\"\\U0001F300-\\U0001F5FF\"  \n",
    "        u\"\\U0001F680-\\U0001F6FF\" \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "\n",
    "text_limpo_a = re.sub(regex_pattern,'',text) \n",
    "\n",
    "re_list = ['@[A-Za-z0–9_]+', '#']\n",
    "combined_re = re.compile( '|'.join( re_list) )\n",
    "text_limpo_b = re.sub(combined_re,'',text_limpo_a)\n",
    "\n",
    "wordcloud = WordCloud(max_words=100, collocation_threshold = 10, width = 1500, height = 1000, random_state = 42, collocations = False, colormap = 'tab10', stopwords = stop_words, background_color=\"white\").generate(text_limpo_b)\n",
    "\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_02_sub3_wordcloud.png\", format='png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6867d0e6",
   "metadata": {},
   "source": [
    "Gráfico de Interpolação de Centralidades - Modularidade 2 \\ Modularidade 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_centralidade_inbound = df_a.query('indegree > 0 & modularity_class == @modularidade')[['Id','eigencentrality', 'pageranks', 'Authority', 'weighted indegree']]\n",
    "df_a_centralidade_inbound = df_a_centralidade_inbound.sort_values(['weighted indegree'], ascending=[False])\n",
    "\n",
    "z = df_a_centralidade_inbound['eigencentrality']\n",
    "x = df_a_centralidade_inbound['pageranks']\n",
    "y = df_a_centralidade_inbound['Authority']\n",
    " \n",
    "fig = plt.figure(figsize = (10, 8))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "   \n",
    "ax.grid( color ='grey', \n",
    "        linestyle ='-.', linewidth = 0.3, \n",
    "        alpha = 0.2) \n",
    " \n",
    " \n",
    "my_cmap = plt.get_cmap('hsv')\n",
    " \n",
    "sctt = ax.scatter3D(x, y, z,\n",
    "                    alpha = 0.8,\n",
    "                    c = (x + y + z), \n",
    "                    s =100,\n",
    "                    cmap = my_cmap, \n",
    "                    marker ='o')\n",
    " \n",
    "plt.title(\"Centralidades aplicadas aos Nodes - Modularidade\")\n",
    "ax.set_xlabel('pageranks', fontweight ='bold') \n",
    "ax.set_ylabel('Authority', fontweight ='bold') \n",
    "ax.set_zlabel('eigencentrality', fontweight ='bold')\n",
    "#fig.colorbar(sctt, ax = ax, shrink = 0.5, aspect = 5)\n",
    "plt.margins(0.2)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_02_sub3_centralidade.png\", format='png')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d29d72",
   "metadata": {},
   "source": [
    "Tabela das 10 contas com maior grau de Centralidade de Entrada - Modularidade 2 \\ Modularidade 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de46b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['Id']=df_c['Id'].str.lower()\n",
    "df_a_centralidade_inbound['Id']=df_a_centralidade_inbound['Id'].str.lower()\n",
    "\n",
    "df_a_centralidade_inbound_classificado = df_a_centralidade_inbound.merge(df_c, on='Id', how='left')\n",
    "df_a_centralidade_inbound_classificado.head(11)\n",
    "\n",
    "dfi.export(\n",
    "    df_a_centralidade_inbound_classificado.head(11),\n",
    "    save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_02_sub3_Tabela_Centralidade.png\",\n",
    "    max_rows = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b279bea",
   "metadata": {},
   "source": [
    "Identificação dos Grupos de Mensagens ligadas as contas indentificadas com os 3 maiores graus de centralidade de entrada - Modularidade 2 \\ Modularidade 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12b62389",
   "metadata": {},
   "outputs": [],
   "source": [
    "nro_outliners = df_a_centralidade_inbound_classificado.head(3)\n",
    "nro_outliners.rename(columns = {'Id':'mention_username'}, inplace = True)\n",
    "col_one_list = nro_outliners['mention_username'].tolist()\n",
    "\n",
    "for indice in col_one_list:\n",
    "    df_b_trab1 = df_b.query('mention_username == @indice')[['author_id', 'mention_username', 'referenced_tweets']]\n",
    "    aux = df_b_trab1['referenced_tweets'].unique()\n",
    "    #print(aux)\n",
    "        \n",
    "    for xx in aux:\n",
    "        # print(xx)\n",
    "        id_tweet_mencao = re.findall('[0-9]+', str(xx))\n",
    "        if id_tweet_mencao != []:\n",
    "            #print(id_tweet_mencao)\n",
    "            retorno_tweet = client.get_tweets(ids=id_tweet_mencao, tweet_fields=['author_id','context_annotations','created_at','geo'])\n",
    "            print(retorno_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce92a50",
   "metadata": {},
   "source": [
    "Carga dos dados - Modularidade 2 \\ Modularidade 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37129751",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv(arq_contas_brasil, sep=';', low_memory = False, index_col=False)\n",
    "\n",
    "modularidade = mod_04            \n",
    "\n",
    "df_a = pd.read_csv(arq_gephi_mod2, low_memory = False, index_col=False)\n",
    "df_b = pd.read_csv(arq_fonte, low_memory = False, index_col=False)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be96d6b",
   "metadata": {},
   "source": [
    "Adequação dos dados - Modularidade 2 \\ Modularidade 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f59968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_trab = pd.DataFrame(df_a, columns = [\"Id\", \"modularity_class\"]) \n",
    "df_a_trab = df_a_trab.query('modularity_class == @modularidade')[['Id', 'modularity_class']]\n",
    "df_a_trab['Id_convert'] = df_a_trab['Id'].astype(str)\n",
    "df_b_trab = pd.DataFrame(df_b, columns = [\"author_id\", \"text\"]) \n",
    "df_b_trab['Id_convert'] = df_b_trab['author_id'].astype(str)\n",
    "df_b_trab.rename(columns = {'author_id':'Id'}, inplace = True)\n",
    "df_merge_inner = pd.merge(df_a_trab, df_b_trab, how = 'inner', on = 'Id_convert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca7e9f",
   "metadata": {},
   "source": [
    "Nuvem de Palavras - Modularidade 2 \\ Modularidade 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71419be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lista_palavras = [\"vai\",\"agora\",\"HTTPS\",\"Se\", \"O\", \"ao\",\"de\",\"a\",\"o\",\"que\",\"e\",\"do\",\"da\",\"em\",\"um\",\"para\",\"é\",\"com\",\"não\",\"uma\",\"os\",\"no\",\"se\",\"na\",\"por\",\"mais\",\"as\",\"dos\",\"como\",\"mas\",\"foi\",\"ao\",\"ele\",\"das\",\"tem\",\"à\",\"seu\",\"sua\",\"ou\",\"ser\",\"quando\",\"muito\",\"há\",\"nos\",\"já\",\"está\",\"eu\",\"também\",\"só\",\"pelo\",\"pela\",\"até\",\"isso\",\"ela\",\"entre\",\"era\",\"depois\",\"sem\",\"mesmo\",\"aos\",\"ter\",\"seus\",\"quem\",\"nas\",\"me\",\"esse\",\"eles\",\"estão\",\"você\",\"tinha\",\"foram\",\"essa\",\"num\",\"nem\",\"suas\",\"meu\",\"às\",\"minha\",\"têm\",\"numa\",\"pelos\",\"elas\",\"havia\",\"seja\",\"qual\",\"será\",\"nós\",\"tenho\",\"lhe\",\"deles\",\"essas\",\"esses\",\"pelas\",\"este\",\"fosse\",\"dele\",\"tu\",\"te\",\"vocês\",\"vos\",\"lhes\",\"meus\",\"minhas\",\"teu\",\"tua\",\"teus\",\"tuas\",\"nosso\",\"nossa\",\"nossos\",\"nossas\",\"dela\",\"delas\",\"esta\",\"estes\",\"estas\",\"aquele\",\"aquela\",\"aqueles\",\"aquelas\",\"isto\",\"aquilo\",\"estou\",\"está\",\"estamos\",\"estão\",\"estive\",\"esteve\",\"estivemos\",\"estiveram\",\"estava\",\"estávamos\",\"estavam\",\"estivera\",\"estivéramos\",\"esteja\",\"estejamos\",\"estejam\",\"estivesse\",\"estivéssemos\",\"estivessem\",\"estiver\",\"estivermos\",\"estiverem\",\"hei\",\"há\",\"havemos\",\"hão\",\"houve\",\"houvemos\",\"houveram\",\"houvera\",\"houvéramos\",\"haja\",\"hajamos\",\"hajam\",\"houvesse\",\"houvéssemos\",\"houvessem\",\"houver\",\"houvermos\",\"houverem\",\"houverei\",\"houverá\",\"houveremos\",\"houverão\",\"houveria\",\"houveríamos\",\"houveriam\",\"sou\",\"somos\",\"são\",\"era\",\"éramos\",\"eram\",\"fui\",\"foi\",\"fomos\",\"foram\",\"fora\",\"fôramos\",\"seja\",\"sejamos\",\"sejam\",\"fosse\",\"fôssemos\",\"fossem\",\"for\",\"formos\",\"forem\",\"serei\",\"será\",\"seremos\",\"serão\",\"seria\",\"seríamos\",\"seriam\",\"tenho\",\"tem\",\"temos\",\"tém\",\"tinha\",\"tínhamos\",\"tinham\",\"tive\",\"teve\",\"tivemos\",\"tiveram\",\"tivera\",\"tivéramos\",\"tenha\",\"tenhamos\",\"tenham\",\"tivesse\",\"tivéssemos\",\"tivesse\",\"tiver\",\"tivermos\",\"tiverem\",\"terei\",\"terá\",\"teremos\",\"terão\",\"teria\",\"teríamos\",\"teriam\",\"Se\",\"RT\",\"se\",\"ao\"]\n",
    "\n",
    "\n",
    "text = \" \".join(i for i in df_merge_inner.text)\n",
    "\n",
    "stop_words = Lista_palavras + list(STOPWORDS)\n",
    "\n",
    "regex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "\n",
    "text_limpo_a = re.sub(regex_pattern,'',text) #replaces pattern with ''\n",
    "\n",
    "re_list = ['@[A-Za-z0–9_]+', '#']\n",
    "combined_re = re.compile( '|'.join( re_list) )\n",
    "text_limpo_b = re.sub(combined_re,'',text_limpo_a)\n",
    "\n",
    "wordcloud = WordCloud(max_words=100, collocation_threshold = 10, width = 1500, height = 1000, random_state = 42, collocations = False, colormap = 'tab10', stopwords = stop_words, background_color=\"white\").generate(text_limpo_b)\n",
    "\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_02_sub4_wordcloud.png\", format='png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346a71b0",
   "metadata": {},
   "source": [
    "Gráfico de Interpolação de Centralidades - Modularidade 2 \\ Modularidade 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9162242",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_centralidade_inbound = df_a.query('indegree > 0 & modularity_class == @modularidade')[['Id','eigencentrality', 'pageranks', 'Authority', 'weighted indegree']]\n",
    "df_a_centralidade_inbound = df_a_centralidade_inbound.sort_values(['weighted indegree'], ascending=[False])\n",
    "\n",
    "z = df_a_centralidade_inbound['eigencentrality']\n",
    "x = df_a_centralidade_inbound['pageranks']\n",
    "y = df_a_centralidade_inbound['Authority']\n",
    " \n",
    "fig = plt.figure(figsize = (10, 8))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "   \n",
    "ax.grid( color ='grey', \n",
    "        linestyle ='-.', linewidth = 0.3, \n",
    "        alpha = 0.2) \n",
    " \n",
    " \n",
    "my_cmap = plt.get_cmap('hsv')\n",
    " \n",
    "sctt = ax.scatter3D(x, y, z,\n",
    "                    alpha = 0.8,\n",
    "                    c = (x + y + z), \n",
    "                    s =100,\n",
    "                    cmap = my_cmap, \n",
    "                    marker ='o')\n",
    " \n",
    "plt.title(\"Centralidades aplicadas aos Nodes - Modularidade\")\n",
    "ax.set_xlabel('pageranks', fontweight ='bold') \n",
    "ax.set_ylabel('Authority', fontweight ='bold') \n",
    "ax.set_zlabel('eigencentrality', fontweight ='bold')\n",
    "#fig.colorbar(sctt, ax = ax, shrink = 0.5, aspect = 5)\n",
    "plt.margins(0.2)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_02_sub4_centralidade.png\", format='png')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a49c08",
   "metadata": {},
   "source": [
    "Tabela das 10 contas com maior grau de Centralidade de Entrada - Modularidade 2 \\ Modularidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494d81a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['Id']=df_c['Id'].str.lower()\n",
    "df_a_centralidade_inbound['Id']=df_a_centralidade_inbound['Id'].str.lower()\n",
    "\n",
    "df_a_centralidade_inbound_classificado = df_a_centralidade_inbound.merge(df_c, on='Id', how='left')\n",
    "df_a_centralidade_inbound_classificado.head(11)\n",
    "\n",
    "dfi.export(\n",
    "    df_a_centralidade_inbound_classificado.head(11),\n",
    "    save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_02_sub4_Tabela_Centralidade.png\",\n",
    "    max_rows = 30\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672b330e",
   "metadata": {},
   "source": [
    "Identificação dos Grupos de Mensagens ligadas as contas indentificadas com os 3 maiores graus de centralidade de entrada - Modularidade 2 \\ Modularidade 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1aa4e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "nro_outliners = df_a_centralidade_inbound_classificado.head(3)\n",
    "nro_outliners.rename(columns = {'Id':'mention_username'}, inplace = True)\n",
    "col_one_list = nro_outliners['mention_username'].tolist()\n",
    "\n",
    "for indice in col_one_list:\n",
    "    df_b_trab1 = df_b.query('mention_username == @indice')[['author_id', 'mention_username', 'referenced_tweets']]\n",
    "    aux = df_b_trab1['referenced_tweets'].unique()\n",
    "    #print(aux)\n",
    "        \n",
    "    for xx in aux:\n",
    "        # print(xx)\n",
    "        id_tweet_mencao = re.findall('[0-9]+', str(xx))\n",
    "        if id_tweet_mencao != []:\n",
    "            #print(id_tweet_mencao)\n",
    "            retorno_tweet = client.get_tweets(ids=id_tweet_mencao, tweet_fields=['author_id','context_annotations','created_at','geo'])\n",
    "            print(retorno_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee04888",
   "metadata": {},
   "source": [
    "Carga dos dados - Modularidade 2 \\ Modularidade 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "72a1426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv(arq_contas_brasil, sep=';', low_memory = False, index_col=False)\n",
    "\n",
    "modularidade = mod_05            \n",
    "\n",
    "df_a = pd.read_csv(arq_gephi_mod2, low_memory = False, index_col=False)\n",
    "df_b = pd.read_csv(arq_fonte, low_memory = False, index_col=False)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd5225a",
   "metadata": {},
   "source": [
    "Adequação dos dados - Modularidade 2 \\ Modularidade 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_trab = pd.DataFrame(df_a, columns = [\"Id\", \"modularity_class\"]) \n",
    "df_a_trab = df_a_trab.query('modularity_class == @modularidade')[['Id', 'modularity_class']]\n",
    "df_a_trab['Id_convert'] = df_a_trab['Id'].astype(str)\n",
    "df_b_trab = pd.DataFrame(df_b, columns = [\"author_id\", \"text\"]) \n",
    "df_b_trab['Id_convert'] = df_b_trab['author_id'].astype(str)\n",
    "df_b_trab.rename(columns = {'author_id':'Id'}, inplace = True)\n",
    "df_merge_inner = pd.merge(df_a_trab, df_b_trab, how = 'inner', on = 'Id_convert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ebe33c",
   "metadata": {},
   "source": [
    "Nuvem de Palavras - Modularidade 2 \\ Modularidade 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2528d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lista_palavras = [\"vai\",\"agora\",\"HTTPS\",\"Se\", \"O\", \"ao\",\"de\",\"a\",\"o\",\"que\",\"e\",\"do\",\"da\",\"em\",\"um\",\"para\",\"é\",\"com\",\"não\",\"uma\",\"os\",\"no\",\"se\",\"na\",\"por\",\"mais\",\"as\",\"dos\",\"como\",\"mas\",\"foi\",\"ao\",\"ele\",\"das\",\"tem\",\"à\",\"seu\",\"sua\",\"ou\",\"ser\",\"quando\",\"muito\",\"há\",\"nos\",\"já\",\"está\",\"eu\",\"também\",\"só\",\"pelo\",\"pela\",\"até\",\"isso\",\"ela\",\"entre\",\"era\",\"depois\",\"sem\",\"mesmo\",\"aos\",\"ter\",\"seus\",\"quem\",\"nas\",\"me\",\"esse\",\"eles\",\"estão\",\"você\",\"tinha\",\"foram\",\"essa\",\"num\",\"nem\",\"suas\",\"meu\",\"às\",\"minha\",\"têm\",\"numa\",\"pelos\",\"elas\",\"havia\",\"seja\",\"qual\",\"será\",\"nós\",\"tenho\",\"lhe\",\"deles\",\"essas\",\"esses\",\"pelas\",\"este\",\"fosse\",\"dele\",\"tu\",\"te\",\"vocês\",\"vos\",\"lhes\",\"meus\",\"minhas\",\"teu\",\"tua\",\"teus\",\"tuas\",\"nosso\",\"nossa\",\"nossos\",\"nossas\",\"dela\",\"delas\",\"esta\",\"estes\",\"estas\",\"aquele\",\"aquela\",\"aqueles\",\"aquelas\",\"isto\",\"aquilo\",\"estou\",\"está\",\"estamos\",\"estão\",\"estive\",\"esteve\",\"estivemos\",\"estiveram\",\"estava\",\"estávamos\",\"estavam\",\"estivera\",\"estivéramos\",\"esteja\",\"estejamos\",\"estejam\",\"estivesse\",\"estivéssemos\",\"estivessem\",\"estiver\",\"estivermos\",\"estiverem\",\"hei\",\"há\",\"havemos\",\"hão\",\"houve\",\"houvemos\",\"houveram\",\"houvera\",\"houvéramos\",\"haja\",\"hajamos\",\"hajam\",\"houvesse\",\"houvéssemos\",\"houvessem\",\"houver\",\"houvermos\",\"houverem\",\"houverei\",\"houverá\",\"houveremos\",\"houverão\",\"houveria\",\"houveríamos\",\"houveriam\",\"sou\",\"somos\",\"são\",\"era\",\"éramos\",\"eram\",\"fui\",\"foi\",\"fomos\",\"foram\",\"fora\",\"fôramos\",\"seja\",\"sejamos\",\"sejam\",\"fosse\",\"fôssemos\",\"fossem\",\"for\",\"formos\",\"forem\",\"serei\",\"será\",\"seremos\",\"serão\",\"seria\",\"seríamos\",\"seriam\",\"tenho\",\"tem\",\"temos\",\"tém\",\"tinha\",\"tínhamos\",\"tinham\",\"tive\",\"teve\",\"tivemos\",\"tiveram\",\"tivera\",\"tivéramos\",\"tenha\",\"tenhamos\",\"tenham\",\"tivesse\",\"tivéssemos\",\"tivesse\",\"tiver\",\"tivermos\",\"tiverem\",\"terei\",\"terá\",\"teremos\",\"terão\",\"teria\",\"teríamos\",\"teriam\",\"Se\",\"RT\",\"se\",\"ao\"]\n",
    "\n",
    "text = \" \".join(i for i in df_merge_inner.text)\n",
    "\n",
    "stop_words = Lista_palavras + list(STOPWORDS)\n",
    "\n",
    "regex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  \n",
    "        u\"\\U0001F300-\\U0001F5FF\"  \n",
    "        u\"\\U0001F680-\\U0001F6FF\" \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "\n",
    "text_limpo_a = re.sub(regex_pattern,'',text) \n",
    "\n",
    "re_list = ['@[A-Za-z0–9_]+', '#']\n",
    "combined_re = re.compile( '|'.join( re_list) )\n",
    "text_limpo_b = re.sub(combined_re,'',text_limpo_a)\n",
    "\n",
    "wordcloud = WordCloud(max_words=100, collocation_threshold = 10, width = 1500, height = 1000, random_state = 42, collocations = False, colormap = 'tab10', stopwords = stop_words, background_color=\"white\").generate(text_limpo_b)\n",
    "\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_02_sub5_wordcloud.png\", format='png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a3c5c",
   "metadata": {},
   "source": [
    "Gráfico de Interpolação de Centralidades - Modularidade 2 \\ Modularidade 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba81362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_centralidade_inbound = df_a.query('indegree > 0 & modularity_class == @modularidade')[['Id','eigencentrality', 'pageranks', 'Authority', 'weighted indegree']]\n",
    "df_a_centralidade_inbound = df_a_centralidade_inbound.sort_values(['weighted indegree'], ascending=[False])\n",
    "\n",
    "z = df_a_centralidade_inbound['eigencentrality']\n",
    "x = df_a_centralidade_inbound['pageranks']\n",
    "y = df_a_centralidade_inbound['Authority']\n",
    " \n",
    "fig = plt.figure(figsize = (10, 8))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "   \n",
    "ax.grid( color ='grey', \n",
    "        linestyle ='-.', linewidth = 0.3, \n",
    "        alpha = 0.2) \n",
    " \n",
    " \n",
    "my_cmap = plt.get_cmap('hsv')\n",
    " \n",
    "sctt = ax.scatter3D(x, y, z,\n",
    "                    alpha = 0.8,\n",
    "                    c = (x + y + z), \n",
    "                    s =100,\n",
    "                    cmap = my_cmap, \n",
    "                    marker ='o')\n",
    " \n",
    "plt.title(\"Centralidades aplicadas aos Nodes - Modularidade\")\n",
    "ax.set_xlabel('pageranks', fontweight ='bold') \n",
    "ax.set_ylabel('Authority', fontweight ='bold') \n",
    "ax.set_zlabel('eigencentrality', fontweight ='bold')\n",
    "#fig.colorbar(sctt, ax = ax, shrink = 0.5, aspect = 5)\n",
    "plt.margins(0.2)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_02_sub5_centralidade.png\", format='png')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a999791a",
   "metadata": {},
   "source": [
    "Tabela das 10 contas com maior grau de Centralidade de Entrada - Modularidade 2 \\ Modularidade 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f912a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['Id']=df_c['Id'].str.lower()\n",
    "df_a_centralidade_inbound['Id']=df_a_centralidade_inbound['Id'].str.lower()\n",
    "\n",
    "df_a_centralidade_inbound_classificado = df_a_centralidade_inbound.merge(df_c, on='Id', how='left')\n",
    "df_a_centralidade_inbound_classificado.head(11)\n",
    "\n",
    "dfi.export(\n",
    "    df_a_centralidade_inbound_classificado.head(11),\n",
    "    save_path + \"\\\\\" + rotulo + \"\\\\\" + rotulo + \"_mod_02_sub5_Tabela_Centralidade.png\",\n",
    "    max_rows = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4476d1",
   "metadata": {},
   "source": [
    "Identificação dos Grupos de Mensagens ligadas as contas indentificadas com os 3 maiores graus de centralidade de entrada - Modularidade 2 \\ Modularidade 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b448cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nro_outliners = df_a_centralidade_inbound_classificado.head(3)\n",
    "nro_outliners.rename(columns = {'Id':'mention_username'}, inplace = True)\n",
    "col_one_list = nro_outliners['mention_username'].tolist()\n",
    "\n",
    "for indice in col_one_list:\n",
    "    df_b_trab1 = df_b.query('mention_username == @indice')[['author_id', 'mention_username', 'referenced_tweets']]\n",
    "    aux = df_b_trab1['referenced_tweets'].unique()\n",
    "    #print(aux)\n",
    "        \n",
    "    for xx in aux:\n",
    "        # print(xx)\n",
    "        id_tweet_mencao = re.findall('[0-9]+', str(xx))\n",
    "        if id_tweet_mencao != []:\n",
    "            #print(id_tweet_mencao)\n",
    "            retorno_tweet = client.get_tweets(ids=id_tweet_mencao, tweet_fields=['author_id','context_annotations','created_at','geo'])\n",
    "            print(retorno_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f0345",
   "metadata": {},
   "source": [
    "A partir desse ponto basta copiar o código e a lógica para se ter a visão das demais modularidades e seus subgrupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e32025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
